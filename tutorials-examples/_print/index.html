<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://neurodesk.org/tutorials-examples/><link rel=alternate type=application/rss+xml href=https://neurodesk.org/tutorials-examples/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=https://neurodesk.org/static/favicons/favicon.ico><link rel=apple-touch-icon href=https://neurodesk.org/static/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=https://neurodesk.org/static/favicons/android-192x192.png sizes=192x192><title>Tutorials & Examples | Neurodesk</title>
<meta name=description content="Tutorials & Examples"><meta property="og:url" content="https://neurodesk.org/tutorials-examples/"><meta property="og:site_name" content="Neurodesk"><meta property="og:title" content="Tutorials & Examples"><meta property="og:description" content="Tutorials & Examples"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Tutorials & Examples"><meta itemprop=description content="Tutorials & Examples"><meta itemprop=dateModified content="2025-10-30T11:09:51+10:00"><meta itemprop=wordCount content="127"><meta name=twitter:card content="summary"><meta name=twitter:title content="Tutorials & Examples"><meta name=twitter:description content="Tutorials & Examples"><link rel=preload href=https://neurodesk.org/scss/main.min.2f0e7dd254a8510650f53c8ffbf7f9af0cc4e0d57d8872fb80c52b2440db9e88.css as=style integrity="sha256-Lw590lSoUQZQ9TyP+/f5rwzE4NV9iHL7gMUrJEDbnog=" crossorigin=anonymous><link href=https://neurodesk.org/scss/main.min.2f0e7dd254a8510650f53c8ffbf7f9af0cc4e0d57d8872fb80c52b2440db9e88.css rel=stylesheet integrity="sha256-Lw590lSoUQZQ9TyP+/f5rwzE4NV9iHL7gMUrJEDbnog=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@docsearch/css@3.8.2 integrity="sha512-l7pkV1dOURFyHCeH8I4fK9lCkQKuqhlsTCqRl3zktifDlB8oTUJ+mJPgYkK9kHpUut8j1iPquTv32t6hvTPv3g==" crossorigin=anonymous><script async src="https://www.googletagmanager.com/gtag/js?id=G-4Z9774J59Y"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4Z9774J59Y")}</script></head><body class=td-section><header><nav class="td-navbar navbar-expand-xl navbar-dark bg-dark"><div class="container-fluid flex-md-row"><a class=navbar-brand href=https://neurodesk.org/><span class="navbar-brand__logo navbar-logo"><svg id="Layer_1" viewBox="0 0 560.3 82.7"><defs><style>.st0{isolation:isolate}.st1{fill:#6ba442}.st2{fill:#fff}</style></defs><g class="st0"><path class="st2" d="M30.2 73.4h-9.9v-60h9.8l33.3 44.8V13.4h10.1v60H63.4L30.1 29.1v44.3z"/><path class="st2" d="M85.8 13.4h45l-1.4 10.3-33.8-.2v13.6l20.1-.2v11.4H95.6v13.5H129l1.8 11.6h-45v-60z"/><path class="st2" d="M141.4 13.4h9.9v50.2h28.2V13.4h9.9v51.4c0 1.2-.2 2.3-.7 3.3-.4 1-1.1 2-1.8 2.7-.8.8-1.7 1.4-2.8 1.8-1.1.4-2.2.7-3.3.7h-30.7c-1.2.0-2.3-.2-3.3-.7-1.1-.4-2-1.1-2.8-1.8-.8-.8-1.4-1.7-1.8-2.7s-.7-2.2-.7-3.3V13.4z"/><path class="st2" d="M244.7 34.8c0 4.6-1.4 7.9-4.3 10-4 2.9-8.4 4.4-13.2 4.4l17.5 24.3h-12.1l-14.7-24h-9.5v24h-8.5V13.4h29.8c10 0 15 4.9 15 14.6v6.8zm-36.3 6h15.2c3.9-.2 6.6-.7 8-1.6 2.6-1.8 3.9-2.9 3.9-3.5V29c0-2.2-.6-3.9-1.7-5-1.4-1.4-3-2.1-4.7-2.1h-20.8v18.9z"/><path class="st2" d="M306.5 59.4c0 4.8-.3 7.7-.6 8.7-.3.9-.9 1.8-1.8 2.8s-1.7 1.3-3.1 1.8c-1.3.5-3.6.7-6.8.7h-27.1c-1.2.0-2.8-.2-5-.6-2.5-.5-3.9-1.1-4.4-1.8-.9-1.5-1.6-2.4-1.8-2.7-.4-.6-.7-3.6-.7-8.7V42.1c0-8.8.0-14.1.2-15.9.0-2.6.3-5 .7-7.4.1-.8.7-1.7 1.7-2.7.6-.7 2.1-1.3 4.4-1.8 1.9-.4 3.5-.7 5-.7h27.1c3.5.0 5.7.1 6.8.6 1.3.5 2.3 1.1 3.1 1.9.9.8 1.5 1.7 2 2.7.4.8.6 3.3.6 7.4l.2 16.7c0 8.1-.1 13.6-.3 16.7zM265.4 23.3v40h31.2v-40h-31.2z"/></g><g class="st0"><path class="st1" d="M316.2 73.4v-60l31.3.3c2.5.0 5.4.6 8.7 1.9 2.6 1 4.8 2.4 6.6 4.3 2 2 3.4 4.2 4.3 6.6 1 3 1.5 5.9 1.5 8.7v17.3c0 3.2-.5 6.1-1.5 8.7s-2.4 4.8-4.2 6.6-4 3.2-6.6 4.2-5.5 1.5-8.7 1.5h-31.3zm30.7-11.2c4.9.0 8-.7 9.2-2 2.1-2.3 3.2-5.8 3.2-10.4v-14c.2-1.9-.2-3.6-1.1-5.2-.8-1.5-1.8-2.8-2.9-3.9-1.1-1.1-2.4-1.9-3.9-2.4-1.5-.6-3-.8-4.4-.8h-21.3v38.8h21.2z"/><path class="st1" d="M381 13.4h45l-1.4 10.3-33.8-.2v13.6l20.1-.2v11.4h-20.1v13.5h33.4l1.8 11.6h-45v-60z"/><path class="st1" d="M446.4 46.5c-1.1.0-2.2-.3-3.3-.7-1.1-.4-2-1.1-2.8-1.8-.8-.8-1.4-1.7-1.8-2.7-.4-1-.7-2.2-.7-3.3V22.1c0-1.2.2-2.3.7-3.3s1.1-2 1.8-2.7 1.7-1.4 2.8-1.8 2.2-.7 3.3-.7h29.1c1.2.0 2.3.2 3.3.7s1.9 1.1 2.7 1.8c1.1 1 1.7 2 1.8 2.8l.7 3.3v6.7l-9 2.7v-7.7h-28.7v14.3l29.1.5c1.2.0 2.3.3 3.3.7 1.1.4 2 1.1 2.8 1.8.8.8 1.4 1.7 1.8 2.7.4 1 .7 2.2.7 3.3V65c0 1.2-.2 2.3-.7 3.3-.4 1-1.1 2-1.8 2.7-.8.8-1.7 1.4-2.7 1.8-1 .4-2.1.7-3.3.7h-30c-1.2.0-2.3-.2-3.3-.7-1.1-.4-2-1.1-2.8-1.8-.8-.8-1.4-1.7-1.8-2.7-.4-1-.7-2.2-.7-3.3v-7.7l9.5-1.6v7.7h28.7V47.2l-28.7-.5z"/><path class="st1" d="M505.4 13.4v23.9l26.2-23.9h12.9l-30.8 27.4 32.1 32.6h-12.9l-27.5-28.1v28.1h-10.6v-60h10.6z"/></g></svg></span></a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#main_navbar aria-controls=main_navbar aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=main_navbar><ul class="navbar-nav ms-auto mt-2 mt-lg-0"><li class="nav-item ml-4 mb-2 mb-lg-0"><a class=nav-link href=https://neurodesk.org/overview/><span>Overview</span></a></li><li class="nav-item ml-4 mb-2 mb-lg-0"><a class=nav-link href=https://neurodesk.org/getting-started/><span>Getting Started</span></a></li><li class="nav-item ml-4 mb-2 mb-lg-0"><a class="nav-link active" href=https://neurodesk.org/tutorials-examples/><span class=active>Tutorials & Examples</span></a></li><li class="nav-item ml-4 mb-2 mb-lg-0"><a class=nav-link href=https://neurodesk.org/developers/><span>Developer Documentation</span></a></li><li class="nav-item ml-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/NeuroDesk target=_blank><span>GitHub</span></a></li><li class="nav-item ml-4 mb-2 mb-lg-0"><a class=nav-link href=https://neurodesk.org/contact/><span>Contact</span></a></li></ul><div class="navbar-nav d-lg-block"><div class=td-search><div class=td-search--algolia id=docsearch-0></div></div></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=https://neurodesk.org/tutorials-examples/>Return to the regular view of this page</a>.</p></div><h1 class=title>Tutorials & Examples</h1><div class=lead>Tutorials & Examples</div><ul><li>1: <a href=#pg-d3c1f24a009aa3cbd38cf549179b8624>Examples</a></li><ul></ul><li>2: <a href=#pg-c9636b4fb3f21abb1d9ddb66ff86b073>Tutorials</a></li><ul><li>2.1: <a href=#pg-db8a97f4b79ed888b4c9b033d4426edf>Electrophysiology</a></li><ul><li>2.1.1: <a href=#pg-f3df167a5725b252a0a08cf0c85a901b>Analysing M/EEG Data with FieldTrip</a></li><li>2.1.2: <a href=#pg-ad6813b64c4bb927062372fedd362756>Analysing EEG Data with MNE</a></li></ul><li>2.2: <a href=#pg-859d01394ae66a2486291b1ddde7ffc1>Functional Imaging</a></li><ul><li>2.2.1: <a href=#pg-67af015aae16d03e2bfd4072735c0c3c>Connectome Workbench</a></li><li>2.2.2: <a href=#pg-5252a206b6f5fbf0682ab2090a437af6>Using fmriprep with neurodesk on an HPC</a></li><li>2.2.3: <a href=#pg-f812ef5ff3c71e17305f2d60c2d0fd5a>Using mriqc with neurodesk on HPC</a></li><li>2.2.4: <a href=#pg-6101cf1003c6047c52a1cabcadcb26f0>PhysIO</a></li><li>2.2.5: <a href=#pg-cfcb6a6641bb38f280f08239d3a4d832>A batch scripting example for PhysIO toolbox</a></li><li>2.2.6: <a href=#pg-493b8ec839ac173dbb80499ac751df6f>Statistical Parametric Mapping (SPM)</a></li></ul><li>2.3: <a href=#pg-9169c9f8aa42ef9f7749cbdd72776eea>MRI phase Processing</a></li><ul><li>2.3.1: <a href=#pg-a145cdccb601a4a078fd1a504694dfb4>Quantitative Susceptibility Mapping</a></li><li>2.3.2: <a href=#pg-b5ea0caa988918c2ca542947f565b20a>SWI</a></li><li>2.3.3: <a href=#pg-6599b665ff2932debfa8480297a31761>Unwrapping</a></li></ul><li>2.4: <a href=#pg-fab12cde1b1cb47d8de34f831eb4e7bb>Multimodal Imaging</a></li><ul><li>2.4.1: <a href=#pg-275f1d8c52f90b8c9042ba260fb946e0>Using MFCSC</a></li></ul><li>2.5: <a href=#pg-e57a258694345082853a63c13b0f1bee>Open Data</a></li><ul><li>2.5.1: <a href=#pg-a9cdb907d2653c4a233e2f7954eb198d>datalad</a></li><li>2.5.2: <a href=#pg-e582735ce6bbb18ef6a0230acdcd54f3>osfclient</a></li></ul><li>2.6: <a href=#pg-975f36ee03d553100bb37c702b1a8519>Programming</a></li><ul><li>2.6.1: <a href=#pg-942fa115fd731c2e10fa187f9f0233d7>Conda environments</a></li><li>2.6.2: <a href=#pg-35b213496a18ca6b677b64b947f54bb8>Matlab</a></li></ul><li>2.7: <a href=#pg-3624cd3076e161d1fbbc4bfcc814e38d>Reproducibility</a></li><ul><li>2.7.1: <a href=#pg-7a7a8485e505bec7f6267a534329dfa7>Reproducible script execution with DataLad</a></li></ul><li>2.8: <a href=#pg-44b4ec1d6c2eb6a75f361c94caac8f65>Spectroscopy</a></li><ul><li>2.8.1: <a href=#pg-16bdca40061ec1ad8bd42400513f337c>Spectroscopy with lcmodel</a></li><li>2.8.2: <a href=#pg-9c021f0163fdf28321444103760ba8ce>Spectroscopy pipeline</a></li></ul><li>2.9: <a href=#pg-7cb11988e9ff6c4a545699afff23592f>Structural Imaging</a></li><ul><li>2.9.1: <a href=#pg-ba2f27cb888361d8d7116fb59180cdad>FreeSurfer</a></li><li>2.9.2: <a href=#pg-f5bb7d50ecc788ed52db3c1c8985c081>Structural connectivity dMRI</a></li></ul></ul><li>3: <a href=#pg-f30f6c05cb5c5bd067c06745b469d13d>Contribute Tutorials and Example Notebooks</a></li><ul><li>3.1: <a href=#pg-2bf6c1d7ca51b83e9ff5c9b3cf6a5f16>Contribute Example Notebooks</a></li><li>3.2: <a href=#pg-17f9fb8a06e3be71418a28e6acd4ee30>Contribute Tutorials</a></li></ul></ul><div class=content><h3 id=1-understand-neurodesk>1. Understand Neurodesk:</h3><p>Neurodesk is a flexible and scalable data analysis environment for reproducible neuroimaging. <a href=https://neurodesk.org/docs/overview>More info</a></p><h3 id=2-choose-your-setup>2. Choose Your Setup:</h3><p>Neurodesk can be used on various platforms including a local PC, High-Performance Computing (HPC), Cloud, and Google Colab. It supports Linux, Mac, and Windows operating systems. You can interact with it through a desktop interface, command line, container, or VSCode. Choose the setup that best suits your needs based on <a href=https://neurodesk.org#startup target=_blank rel=noopener>this table</a>.</p><h3 id=3-follow-the-instructions>3. Follow the Instructions:</h3><p>Once you&rsquo;ve chosen your setup, follow the instructions provided in the link.</p><p>For example, if you&rsquo;re using Linux on a local PC with a desktop interface, you would follow the instructions at <a href=https://neurodesk.org/docs/getting-started/neurodesktop/linux/ target=_blank rel=noopener>https://neurodesk.org/docs/getting-started/neurodesktop/linux/</a>.</p><div style=max-width:900px;margin-left:0><img src=https://neurodesk.org/static/tutorials-examples/startup_table.png alt=startup style=width:100%;height:auto></div><h2 id=4-video-tutorial>4. Video tutorial</h2><p>See below for a 4-minute tutorial on Installation, Usage and Data Access with Neurodesktop</p><div style=max-width:900px;margin-left:0><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/BffOZcV2oaY?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d3c1f24a009aa3cbd38cf549179b8624>1 - Examples</h1><p><strong><a href=https://neurodesk.org/example-notebooks/intro.html target=_blank rel="noopener noreferrer">Explore the Example Notebooks →</a></strong></p><hr><p><a href=https://neurodesk.org/docs/getting-started target=_blank rel=noopener>Install Neurodesk</a> and you can load these example notebooks directly in the environment to try them out.</p><p>When you install the NeurodeskApp, You can find them under <code>example-notebooks/books</code>.</p><p><img src=https://neurodesk.org/static/tutorials-examples/examples/NeurodeskApp-example.png alt=button></p><p>We provide a collection of example Jupyter notebooks to help you get started with Neurodesk and explore its capabilities. These notebooks cover various use cases and analyses.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c9636b4fb3f21abb1d9ddb66ff86b073>2 - Tutorials</h1><div class=lead>Tutorials</div></div><div class=td-content><h1 id=pg-db8a97f4b79ed888b4c9b033d4426edf>2.1 - Electrophysiology</h1><div class=lead>Tutorials about processing of EEG/MEG/ECoG data</div></div><div class=td-content><h1 id=pg-f3df167a5725b252a0a08cf0c85a901b>2.1.1 - Analysing M/EEG Data with FieldTrip</h1><div class=lead>A brief guide to using FieldTrip to analyse electrophysiological data within neurodesk.</div><blockquote><p><em>This tutorial was created by Judy D Zhu.</em></p><p>Email: <a href=mailto:judyzhud@gmail.com>judyzhud@gmail.com</a></p><p>Github: @JD-Zhu</p><p>Twitter: @JudyDZhu</p></blockquote><hr><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>Please note that this container uses a compiled version of FieldTrip to run scripts (without needing a Matlab license). Code development is not currently supported within the container and needs to be carried out separately in Matlab.<br><br></p><h2 id=getting-started>Getting started</h2><ol><li>Navigate to Neurodesk->Electrophysiology->fieldtrip->fieldtrip20211114 in the menu:</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/fieldtrip/1_menu.png alt=1_menu title=1_menu></p><p>Once this window is loaded, you are ready to go:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/fieldtrip/2_container.PNG alt=2_container title=2_container></p><br><ol start=2><li>Type the following into the command window (replacing &ldquo;./yourscript.m&rdquo; with the name of your custom script - if the script is in the current folder, use &ldquo;./&rdquo; before the script name like in the example; otherwise, please supply the full path):</li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>run_fieldtrip.sh /opt/MCR/v99 ./yourscript.m</span></span></code></pre></div></div><p>For example, here we ran a script to browse some raw data:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/fieldtrip/3_running.PNG alt=3_running title=3_running></p><p>The fieldtrip GUI is displayed automatically and functions as it normally would when running inside Matlab.</p><p>NOTES:</p><ol><li>The script can only call FieldTrip and SPM functions (these are the only functions in the search path, and the search path cannot be altered using addpath)</li><li>The script cannot include internal functions</li><li>The script can use all the MATLAB toolboxes included in the compiled version of FieldTrip</li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-ad6813b64c4bb927062372fedd362756>2.1.2 - Analysing EEG Data with MNE</h1><div class=lead>Use mne-python to load, pre-process, and plot example EEG data in a jupyter notebook through vscode.</div><hr><blockquote><p><em>This tutorial was created by Angela Renton.</em></p><p>Github: @air2310</p></blockquote><hr><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=getting-started>Getting started</h2><p>To begin, navigate to Neurodesk->Electrophysiology->mne->vscodeGUI 0.23.4 in the menu. This version of vscode has been installed in a software container together with the a conda environment containing MNE-python. Note that if you open any other version of vscode in Neurodesk, you will not be able to access the MNE conda environment.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut0.png alt=EEGtut0 title=EEGtut0></p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut1.png alt=EEGtut1 title=EEGtut1></p><p>Open the folder: “/home/user/Desktop/storage” or a subfolder in which you would like to store this demo. In this folder, create a new file named “EEGDemo.ipynb” or something similar:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut2.png alt=EEGtut2 title=EEGtut2></p><p>If this is your first time opening a Jupyter notebook on vscode in neurodesktop, you may see the following popup. If so, click “install” to install the vscode extensions for Jupyter.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut3.png alt=EEGtut3 title=EEGtut3></p><h2 id=select-mne-python-kernel>Select MNE python kernel</h2><p>Next, we need to direct vscode to use the python kernel associated with MNE. In the top right corner of your empty jupyter notebook, click “Select Kernel”:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut4.png alt=EEGtut4 title=EEGtut4></p><p>Then, select mne-0.23.4 from the dropdown menu, which should look something like this:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut5.png alt=EEGtut5 title=EEGtut5></p><h2 id=activate-the-mne-conda-environment-in-the-terminal>Activate the MNE conda environment in the terminal</h2><p>Next, we&rsquo;ll activate the same MNE environment in a terminal. From the top menu in vscode, select Terminal->New Terminal, or hit [Ctrl]+[Shift]+[`].</p><p>If this is your first time using vscode in this container, you may have to initialise conda by typing <code>conda init bash</code> in the bash terminal. After initialising bash, you will have to close and then reopen the terminal.</p><p>Once you have initialised conda, you can activate the MNE environment in the terminal:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>conda activate mne-0.23.4</span></span></code></pre></div></div><p>You should now see &ldquo;(mne-0.23.4)&rdquo; ahead of the current line in the terminal.</p><h2 id=download-sample-data>Download sample data</h2><p>In the terminal (in which you have activated the MNE environment), input the following code to download some BIDS formatted sample EEG data:</p><blockquote><p>Remember to update the path to the location you are storing this tutorial!</p></blockquote><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>pip install osfclient
</span></span><span style=display:flex><span>osf -p C689U fetch Data_sample.zip /neurodesktop-storage/EEGDEMO/Data_sample.zip
</span></span><span style=display:flex><span>unzip Data_sample.zip </span></span></code></pre></div></div><p>This is a small dataset with only 5 EEG channels from a single participant. The participant is viewing a frequency tagged display and is cued to attend to dots tagged at one frequency or another (6 Hz, 7.5 Hz) for long, 15 s trials. To read more about the dataset, click <a href=https://osf.io/c689u/ target=_blank rel=noopener>here</a></p><h2 id=plotting-settings>Plotting settings</h2><p>To make sure our plots retain their interactivity, set the following line at the top of your notebook:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>%matplotlib qt</span></span></code></pre></div></div><p>This will mean your figures pop out as individual, interactive plots that will allow you to explore the data, rather than as static, inline plots. You can switch “qt” to “inline” to switch back to default, inline plotting.</p><h2 id=loading-and-processing-data>Loading and processing data</h2><blockquote><p>NOTE: MNE has many helpful tutorials which delve into data processing and analysis using MNE-python in much further detail. These can be found <a href=https://mne.tools/stable/auto_tutorials/index.html target=_blank rel=noopener>here</a></p></blockquote><p>Begin by importing the necessary modules and creating a pointer to the data:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#57606a># Interactive plotting</span>
</span></span><span style=display:flex><span><span style=color:#0550ae>%</span>matplotlib qt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># Import modules</span>
</span></span><span style=display:flex><span>import os
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import mne
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># Load data</span>
</span></span><span style=display:flex><span>sample_data_folder <span style=color:#0550ae>=</span> <span style=color:#0a3069>&#39;/neurodesktop-storage/EEGDemo/Data_sample&#39;</span>
</span></span><span style=display:flex><span>sample_data_raw_file <span style=color:#0550ae>=</span> os<span style=color:#0550ae>.</span>path<span style=color:#0550ae>.</span>join<span style=color:#1f2328>(</span>sample_data_folder<span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;sub-01&#39;</span><span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;eeg&#39;</span><span style=color:#1f2328>,</span>
</span></span><span style=display:flex><span>                                    <span style=color:#0a3069>&#39;sub-01_task-FeatAttnDec_eeg.vhdr&#39;</span><span style=color:#1f2328>)</span>
</span></span><span style=display:flex><span>raw <span style=color:#0550ae>=</span> mne<span style=color:#0550ae>.</span>io<span style=color:#0550ae>.</span>read_raw_brainvision<span style=color:#1f2328>(</span>sample_data_raw_file <span style=color:#1f2328>,</span> <span style=color:#6639ba>preload</span><span style=color:#0550ae>=</span>True<span style=color:#1f2328>)</span></span></span></code></pre></div></div><p>the raw.info structure contains information about the dataset:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Display data info
</span></span><span style=display:flex><span>print(raw)
</span></span><span style=display:flex><span>print(raw.info)</span></span></code></pre></div></div><p>This data file did not include a montage. Lets create one using standard values for the electrodes we have:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Create montage
</span></span><span style=display:flex><span>montage = {&#39;Iz&#39;:  [0, -110, -40],
</span></span><span style=display:flex><span>            &#39;Oz&#39;: [0, -105, -15],
</span></span><span style=display:flex><span>            &#39;POz&#39;: [0,   -100, 15],
</span></span><span style=display:flex><span>            &#39;O1&#39;: [-40, -106, -15],
</span></span><span style=display:flex><span>            &#39;O2&#39;:  [40, -106, -15],
</span></span><span style=display:flex><span> }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>montageuse = mne.channels.make_dig_montage(ch_pos=montage, lpa=[-82.5, -19.2, -46], nasion=[0, 83.2, -38.3], rpa=[82.2, -19.2, -46]) # based on mne help file on setting 10-20 montage</span></span></code></pre></div></div><p>Next, lets visualise the data.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>raw.plot()</span></span></code></pre></div></div><p>This should open an interactive window in which you can scroll through the data. See the MNE documentation for help on how to customise this plot.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut6.png alt=EEGtut6 title=EEGtut6></p><p>If, upon visual inspection, you decide to exclude one of the channels, you can specify this in raw.info[‘bads’] now. For example:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>raw.info[&#39;bads&#39;] = [&#39;POz&#39;]</span></span></code></pre></div></div><p>Next, we’ll extract our events. The trigger channel in this file is incorrectly scaled, so we’ll correct that before we extract our events:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Correct trigger scaling
</span></span><span style=display:flex><span>trigchan = raw.copy()
</span></span><span style=display:flex><span>trigchan = trigchan.pick(&#39;TRIG&#39;)
</span></span><span style=display:flex><span>trigchan._data = trigchan._data*1000000
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Extract events
</span></span><span style=display:flex><span>events = mne.find_events(trigchan, stim_channel=&#39;TRIG&#39;, consecutive=True, initial_event=True, verbose=True)
</span></span><span style=display:flex><span>print(&#39;Found %s events, first five:&#39; % len(events))
</span></span><span style=display:flex><span>print(events[:5])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Plot events
</span></span><span style=display:flex><span>mne.viz.plot_events(events, raw.info[&#39;sfreq&#39;], raw.first_samp)</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut7.png alt=EEGtut7 title=EEGtut7></p><p>Now that we’ve extracted our events, we can extract our EEG channels and do some simple pre-processing:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># select
</span></span><span style=display:flex><span>eeg_data = raw.copy().pick_types(eeg=True, exclude=[&#39;TRIG&#39;])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Set montage
</span></span><span style=display:flex><span>eeg_data.info.set_montage(montageuse)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Interpolate
</span></span><span style=display:flex><span>eeg_data_interp = eeg_data.copy().interpolate_bads(reset_bads=True) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Filter Data
</span></span><span style=display:flex><span>eeg_data_interp.filter(l_freq=1, h_freq=45, h_trans_bandwidth=0.1)</span></span></code></pre></div></div><p>Let’s visualise our data again now that it’s cleaner:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#plot results again, this time with some events and scaling. 
</span></span><span style=display:flex><span>eeg_data_interp.plot(events=events, duration=10.0, scalings=dict(eeg=0.00005), color=&#39;k&#39;, event_color=&#39;r&#39;)</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut8.png alt=EEGtut8 title=EEGtut8></p><p>That’s looking good! We can even see hints of the frequency tagging. It’s about time to epoch our data.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Epoch to events of interest
</span></span><span style=display:flex><span>event_id = {&#39;attend 6Hz K&#39;: 23, &#39;attend 7.5Hz K&#39;:  27}  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Extract 15 s epochs relative to events, baseline correct, linear detrend, and reject 
</span></span><span style=display:flex><span># epochs where eeg amplitude is &gt; 400
</span></span><span style=display:flex><span>epochs = mne.Epochs(eeg_data_interp, events, event_id=event_id, tmin=0,
</span></span><span style=display:flex><span>                    tmax=15, baseline=(0, 0), reject=dict(eeg=0.000400), detrend=1)  
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Drop bad trials
</span></span><span style=display:flex><span>epochs.drop_bad()</span></span></code></pre></div></div><p>We can average these epochs to form Event Related Potentials (ERPs):</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Average erpochs to form ERPs
</span></span><span style=display:flex><span>attend6 = epochs[&#39;attend 6Hz K&#39;].average()
</span></span><span style=display:flex><span>attend75 = epochs[&#39;attend 7.5Hz K&#39;].average()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Plot ERPs
</span></span><span style=display:flex><span>evokeds = dict(attend6=list(epochs[&#39;attend 6Hz K&#39;].iter_evoked()),
</span></span><span style=display:flex><span>               attend75=list(epochs[&#39;attend 7.5Hz K&#39;].iter_evoked()))
</span></span><span style=display:flex><span>mne.viz.plot_compare_evokeds(evokeds, combine=&#39;mean&#39;)</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut9.png alt=EEGtut9 title=EEGtut9></p><p>In this plot, we can see that the data are frequency tagged. While these data were collected, the participant was performing an attention task in which two visual stimuli were flickering at 6 Hz and 7.5 Hz respectively. On each trial the participant was cued to monitor one of these two stimuli for brief bursts of motion. From previous research, we expect that the steady-state visual evoked potential (SSVEP) should be larger at the attended frequency than the unattended frequency. Lets check if this is true.</p><p>We&rsquo;ll begin by exporting our epoched EEG data to a numpy array</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># Preallocate
</span></span><span style=display:flex><span>n_samples = attend6.data.shape[1]
</span></span><span style=display:flex><span>sampling_freq = 1200 # sampling frequency
</span></span><span style=display:flex><span>epochs_np = np.empty((n_samples, 2) )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Get data - averaging across EEG channels
</span></span><span style=display:flex><span>epochs_np[:,0] = attend6.data.mean(axis=0)
</span></span><span style=display:flex><span>epochs_np[:,1] = attend75.data.mean(axis=0)</span></span></code></pre></div></div><p>Next, we can use a Fast Fourier Transform (FFT) to transform the data from the time domain to the frequency domain. For this, we&rsquo;ll need to import the FFT packages from scipy:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>from scipy.fft import fft, fftfreq, fftshift
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># Get FFT
</span></span><span style=display:flex><span>fftdat = np.abs(fft(epochs_np, axis=0)) / n_samples
</span></span><span style=display:flex><span>freq = fftfreq(n_samples, d=1 / sampling_freq)  # get frequency bins</span></span></code></pre></div></div><p>Now that we have our frequency transformed data, we can plot our two conditions to assess whether attention altered the SSVEP amplitudes:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig,ax = plt.subplots(1, 1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ax.plot(freq, fftdat[:,0], &#39;-&#39;, label=&#39;attend 6Hz&#39;, color=[78 / 255, 185 / 255, 159 / 255])  
</span></span><span style=display:flex><span>ax.plot(freq, fftdat[:,1], &#39;-&#39;, label=&#39;attend 7.5Hz&#39;, color=[236 / 255, 85 / 255, 58 / 255])  
</span></span><span style=display:flex><span>ax.set_xlim(4, 17)
</span></span><span style=display:flex><span>ax.set_ylim(0, 1e-6)
</span></span><span style=display:flex><span>ax.set_title(&#39;Frequency Spectrum&#39;)
</span></span><span style=display:flex><span>ax.legend()</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/electrophysiology/eeg_mne-python/EEGtut10.PNG alt=EEGtut10 title=EEGtut10></p><p>This plot shows that the SSVEPs were indeed modulated by attention in the direction we would expect! Congratulations! You’ve run your first analysis of EEG data in neurodesktop.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-859d01394ae66a2486291b1ddde7ffc1>2.2 - Functional Imaging</h1><div class=lead>Tutorials about processing functional MRI data</div></div><div class=td-content><h1 id=pg-67af015aae16d03e2bfd4072735c0c3c>2.2.1 - Connectome Workbench</h1><div class=lead>A tutorial for accessing and visualizing the 7T HCP Retinotopy Dataset on Connectome Workbench.</div><blockquote><p><em>This tutorial was created by Fernanda L. Ribeiro.</em></p><p>Email: <a href=mailto:fernanda.ribeiro@uq.edu.au>fernanda.ribeiro@uq.edu.au</a></p><p>Github: @felenitaribeiro</p><p>Twitter: @NandaRibeiro93</p></blockquote><p>This tutorial documents how to use Connectome Workbench on NeuroDesk for visualizing the 7T HCP Retinotopy Dataset.</p><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=download-data>Download data</h2><ol><li><p>First, make sure you register for the Human Connectome Project Open Access Data: <a href=https://www.humanconnectome.org/study/hcp-young-adult/data-use-terms target=_blank rel=noopener>https://www.humanconnectome.org/study/hcp-young-adult/data-use-terms</a></p></li><li><p>Register to the BALSA database: <a href=https://balsa.wustl.edu/ target=_blank rel=noopener>https://balsa.wustl.edu/</a>.</p></li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/1_balsa.png alt=1_balsa title=1_balsa></p><ol start=3><li>Login and download the scene files containing the retinotopic maps available at: <a href=https://balsa.wustl.edu/study/9Zkk target=_blank rel=noopener>https://balsa.wustl.edu/study/9Zkk</a>.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/2_balsa.png alt=2_balsa title=2_balsa></p><p>These files include preprocessed collated data from 181 participants, including retinotopic, curvature, midthickness, and myelin maps.</p><ol start=4><li>Finally, unzip the S1200_7T_Retinotopy_9Zkk.zip file.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/3_unzip.png alt=3_unzip title=3_unzip></p><h2 id=visualizing-scene-files>Visualizing scene files</h2><p>Using Connectome Workbench, you can load &ldquo;.scene&rdquo; files and visualize all individuals&rsquo; retinotopic maps.
To do so, follow the next steps:</p><ol><li>In the application menu, navigate to Neurodesk → functional imaging → connectomeworkbench → connectomeworkbench 1.5.0</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/4_appmenu.png alt=4_appmenu title=4_appmenu></p><ol start=2><li>On the terminal shell that pops up, type in:</li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wb_view</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/5_wbview.png alt=5_wbview title=5_wbview></p><ol start=3><li>Click on &ldquo;Open Other&rdquo;</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/6_openother.png alt=6_openother title=6_openother></p><p>and search for a scene file</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/7_scenefile.png alt=7_scenefile title=7_scenefile></p><p>in the path where your data is</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/8_path.png alt=8_path title=8_path></p><p>Finally, select the desired file and open it:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/9_file.png alt=9_file title=9_file></p><ol start=4><li>On the &lsquo;Scenes&rsquo; window that will pop up, select the first option.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/10_scene.png alt=10_scene title=10_scene></p><p>The default images are the average maps.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/11_loadedscene.png alt=11_loadedscene title=11_loadedscene></p><ol start=5><li>To change the displayed images for an individual’s data instead, click on the first ticked dropdown menu</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/12_fileselection.png alt=12_fileselection title=12_fileselection></p><p>and select &ldquo;S1200_7T_Retinotopy181.All.Fit1_PolarAngle_MSMALL.32k_fs_LR.dscalar.nii&rdquo;:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/13_polarAngleALL.png alt=13_polarAngleALL title=13_polarAngleALL></p><ol start=6><li>Now, you should be able to select specific maps from the dropdown menu on the right. For example, here we have the first individual polar angle map (top left):</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/14_index1.png alt=14_index1 title=14_index1></p><p>Now we have the fifth:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/14_index5.png alt=14_index5 title=14_index5></p><ol start=7><li>You can do the same for the other functional maps by navigating through the tabs at the top.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/15_tabs.png alt=15_tabs title=15_tabs></p></div><div class=td-content style=page-break-before:always><h1 id=pg-5252a206b6f5fbf0682ab2090a437af6>2.2.2 - Using fmriprep with neurodesk on an HPC</h1><div class=lead>A brief guide to using fmriprep with neurodesk</div><blockquote><p><em>This tutorial was created by Kelly G. Garner.</em></p><p>Github: <a href=https://github.com/garner-code target=_blank rel=noopener>@kel_github</a></p></blockquote><blockquote><p>This workflow documents how to use fmriprep with neurodesk and provides some details that may help you troubleshoot some common problems I found along the way.</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><blockquote><p><em>An example notebook can be found here:</em>
<a href=https://github.com/NeuroDesk/example-notebooks/blob/main/books/functional_imaging/fmriprep.ipynb target=_blank rel=noopener>https://github.com/NeuroDesk/example-notebooks/blob/main/books/functional_imaging/fmriprep.ipynb</a></p></blockquote><hr><h1 id=assumptions>Assumptions</h1><ul><li><input disabled type=checkbox> Your data is already in <a href=https://bids.neuroimaging.io/ target=_blank rel=noopener>BIDS format</a></li><li><input disabled type=checkbox> You plan to run fmriprep using Neurodesk</li><li><input disabled type=checkbox> You have a copy of the freesurfer license file (freesurfer.txt), that can be read from the file system using Neurodesk</li></ul><hr><h1 id=steps>Steps</h1><h2 id=launch-neurodesk>Launch Neurodesk</h2><p>From the launcher, click the Neurodesktop icon:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/fmriprep/launch_neurodesk.png alt=launch_neurodesk title=launch_neurodesk></p><h2 id=open-fmriprep>Open fmriprep</h2><p>Now you&rsquo;re in Neurodesk, use the menus to first open the neurodesk options</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/fmriprep/neurodesk_menu.png alt=neurodesk_menu title=neurodesk_menu></p><p>and then select fMRIPrep. Note that the latest version will be the lowest on the dropdown list:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/fmriprep/open_fmriprep.png alt=open_fmriprep title=open_fmriprep></p><p>This will open a terminal window where fMRIPrep is ready and waiting at your fingertips - woohoo!</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/fmriprep/fmriprep_bash.png alt=fmriprep_bash title=fmriprep_bash></p><h2 id=setting-up-fmriprep-command>Setting up fmriprep command</h2><p>You can now enter your fmriprep command straight into the command line in the newly opened terminal. Here is a quick guide to the command I have used with the options I have found most useful. Note that fMRIPrep requests the path to the freesurfer license file, which should be somewhere in your system for neurodesk to read - e.g. in &rsquo;neurodesktop-storage'.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6639ba>export</span> <span style=color:#953800>ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS</span><span style=color:#0550ae>=</span><span style=color:#0550ae>6</span> <span style=color:#57606a># specify the number of threads you want to use</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fmriprep /path/to/your/data <span style=color:#0a3069>\ </span><span style=color:#57606a># this is the top level of your data folder</span>
</span></span><span style=display:flex><span>         /path/to/your/data/derivatives <span style=color:#0a3069>\ </span><span style=color:#57606a># where you want fmriprep output to be saved</span>
</span></span><span style=display:flex><span>         participant <span style=color:#0a3069>\ </span><span style=color:#57606a># this tells fmriprep to analyse at the participant level</span>
</span></span><span style=display:flex><span>         --fs-license-file /path/to/your/freesurfer.txt <span style=color:#0a3069>\ </span><span style=color:#57606a># where the freesurfer license file is</span>
</span></span><span style=display:flex><span>         --output-spaces T1w MNI152NLin2009cAsym fsaverage fsnative <span style=color:#0a3069>\ </span>
</span></span><span style=display:flex><span>         --participant-label <span style=color:#0550ae>01</span> <span style=color:#0a3069>\ </span><span style=color:#57606a># put what ever participant labels you want to analyse</span>
</span></span><span style=display:flex><span>         --nprocs <span style=color:#0550ae>6</span> --mem <span style=color:#0550ae>10000</span> <span style=color:#0a3069>\ </span><span style=color:#57606a># fmriprep can be greedy on the hpc, make sure it is not</span>
</span></span><span style=display:flex><span>         --skip_bids_validation <span style=color:#0a3069>\ </span><span style=color:#57606a># its normally fine to skip this but do make sure your data are BIDS enough</span>
</span></span><span style=display:flex><span>         -v <span style=color:#57606a># be verbal fmriprep, tell me what you are doing</span></span></span></code></pre></div></div><p>Then hit return and fMRIPrep should now be merrily working away on your data :)</p><hr><h2 id=some-common-pitfalls-i-have-learned-from-my-mistakes-and-sometimes-from-others>Some common pitfalls I have learned from my mistakes (and sometimes from others)</h2><ol><li><p>If fmriprep hangs it could well be that you are out of disk space. Sometimes this is because fmriprep created a work directory in your home folder which is often limited on the HPC. Make sure fmriprep knows to use a work drectory in your scratch. you can specify this in the fmriprep command by using -w /path/to/the/work/directory/you/made</p></li><li><p>I learned the following from TomCat (@thomshaw92) - fMRIPrep can get confused between subjects when run in parallel. Parallelise with caution.</p></li><li><p>If running on a HPC, make sure to set the processor and memory limits, if not your job will get killed because it hogs all the resources.</p></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-f812ef5ff3c71e17305f2d60c2d0fd5a>2.2.3 - Using mriqc with neurodesk on HPC</h1><div class=lead>A brief guide to using mriqc with neurodesk.</div><blockquote><p><em>This tutorial was created by Kelly G. Garner.</em></p><p>Github: <a href=https://github.com/garner-code target=_blank rel=noopener>@kel_github</a></p></blockquote><blockquote><p>This workflow documents how to use MRIQC with neurodesk and provides some details that may help you troubleshoot some common problems I found along the way.</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><hr><h1 id=assumptions>Assumptions</h1><ul><li><input disabled type=checkbox> Your data is already in <a href=https://bids.neuroimaging.io/ target=_blank rel=noopener>BIDS format</a></li><li><input disabled type=checkbox> You plan to run mriqc using Neurodesk</li></ul><p>NOTE: MRIQC has its $HOME variable hardcoded to be /home/mriqc. This leads to problems on some HPCs. A workaround is to run this before mriqc:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#cf222e>export</span> neurodesk_singularity_opts<span style=color:#0550ae>=</span><span style=color:#0a3069>&#34;--home $HOME:/home&#34;</span></span></span></code></pre></div></div><hr><h1 id=steps>Steps</h1><hr><h2 id=launch-neurodesk>Launch Neurodesk</h2><p>From the launcher, click the Neurodesktop icon:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/mriqc/launch_neurodesk.png alt=launch_neurodesk title=launch_neurodesk></p><h2 id=open-mriqc>Open MRIQC</h2><p>Now you&rsquo;re in Neurodesk, use the menus to first open the neurodesk options</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/mriqc/neurodesk_menu.png alt=neurodesk_menu title=neurodesk_menu></p><p>and then select MRIQC. Note that the latest version will be the lowest on the dropdown list:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/mriqc/open_mriqc.png alt=open_mriqc title=open_mriqc></p><p>This will open a terminal window where MRIQC is ready and waiting at your fingertips - woohoo!</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/mriqc/mriqc_bash.png alt=mriqc_bash title=mriqc_bash></p><h2 id=setting-up-mriqc-command>Setting up mriqc command</h2><p>You can now enter the following mriqc commands straight into the command line in the newly opened terminal window.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#1f2328>export</span> <span style=color:#1f2328>ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS</span><span style=color:#1f2328>=</span><span style=color:#0550ae>6</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>specify</span> <span style=color:#1f2328>the</span> <span style=color:#1f2328>number</span> <span style=color:#1f2328>of</span> <span style=color:#1f2328>threads</span> <span style=color:#1f2328>you</span> <span style=color:#1f2328>want</span> <span style=color:#1f2328>to</span> <span style=color:#1f2328>use</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#1f2328>mriqc</span> <span style=color:#0550ae>/</span><span style=color:#1f2328>path</span><span style=color:#0550ae>/</span><span style=color:#1f2328>to</span><span style=color:#0550ae>/</span><span style=color:#1f2328>your</span><span style=color:#0550ae>/</span><span style=color:#1f2328>data</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>this</span> <span style=color:#1f2328>is</span> <span style=color:#1f2328>the</span> <span style=color:#1f2328>top</span> <span style=color:#1f2328>level</span> <span style=color:#1f2328>of</span> <span style=color:#1f2328>your</span> <span style=color:#1f2328>data</span> <span style=color:#1f2328>folder</span>
</span></span><span style=display:flex><span>         <span style=color:#0550ae>/</span><span style=color:#1f2328>path</span><span style=color:#0550ae>/</span><span style=color:#1f2328>to</span><span style=color:#0550ae>/</span><span style=color:#1f2328>your</span><span style=color:#0550ae>/</span><span style=color:#1f2328>data</span><span style=color:#0550ae>/</span><span style=color:#1f2328>derivatives</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>where</span> <span style=color:#1f2328>you</span> <span style=color:#1f2328>want</span> <span style=color:#1f2328>mriqc</span> <span style=color:#1f2328>output</span> <span style=color:#1f2328>to</span> <span style=color:#1f2328>be</span> <span style=color:#1f2328>saved</span>
</span></span><span style=display:flex><span>         <span style=color:#1f2328>participant</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>this</span> <span style=color:#1f2328>tells</span> <span style=color:#1f2328>mriqc</span> <span style=color:#1f2328>to</span> <span style=color:#1f2328>analyse</span> <span style=color:#1f2328>at</span> <span style=color:#1f2328>the</span> <span style=color:#1f2328>participant</span> <span style=color:#1f2328>level</span>
</span></span><span style=display:flex><span>         <span style=color:#0550ae>--</span><span style=color:#1f2328>participant</span><span style=color:#0550ae>-</span><span style=color:#1f2328>label</span> <span style=color:#0550ae>01</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>put</span> <span style=color:#1f2328>what</span> <span style=color:#1f2328>ever</span> <span style=color:#1f2328>participant</span> <span style=color:#1f2328>labels</span> <span style=color:#1f2328>you</span> <span style=color:#1f2328>want</span> <span style=color:#1f2328>to</span> <span style=color:#1f2328>analyse</span>
</span></span><span style=display:flex><span>         <span style=color:#0550ae>--</span><span style=color:#1f2328>work</span><span style=color:#0550ae>-</span><span style=color:#1f2328>dir</span> <span style=color:#0550ae>/</span><span style=color:#1f2328>path</span><span style=color:#0550ae>/</span><span style=color:#1f2328>to</span><span style=color:#0550ae>/</span><span style=color:#1f2328>work</span><span style=color:#0550ae>/</span><span style=color:#1f2328>directory</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span><span style=color:#1f2328>useful</span> <span style=color:#1f2328>to</span> <span style=color:#1f2328>specify</span> <span style=color:#1f2328>so</span> <span style=color:#1f2328>your</span> <span style=color:#1f2328>home</span> <span style=color:#1f2328>directory</span> <span style=color:#1f2328>definitely</span> <span style=color:#1f2328>does</span> <span style=color:#1f2328>not</span> <span style=color:#1f2328>get</span> <span style=color:#1f2328>clogged</span>
</span></span><span style=display:flex><span>         <span style=color:#0550ae>--</span><span style=color:#1f2328>nprocs</span> <span style=color:#0550ae>6</span> <span style=color:#0550ae>--</span><span style=color:#1f2328>mem_gb</span> <span style=color:#0550ae>10000</span> <span style=color:#f6f8fa;background-color:#82071e>\</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>mriqc</span> <span style=color:#1f2328>can</span> <span style=color:#1f2328>be</span> <span style=color:#1f2328>greedy</span> <span style=color:#1f2328>on</span> <span style=color:#1f2328>the</span> <span style=color:#1f2328>hpc</span><span style=color:#1f2328>,</span> <span style=color:#1f2328>make</span> <span style=color:#1f2328>sure</span> <span style=color:#1f2328>it</span> <span style=color:#1f2328>is</span> <span style=color:#1f2328>not</span>
</span></span><span style=display:flex><span>         <span style=color:#0550ae>-</span><span style=color:#1f2328>v</span> <span style=color:#f6f8fa;background-color:#82071e>#</span> <span style=color:#1f2328>be</span> <span style=color:#1f2328>verbal</span> <span style=color:#1f2328>mriqc</span><span style=color:#1f2328>,</span> <span style=color:#1f2328>tell</span> <span style=color:#1f2328>me</span> <span style=color:#1f2328>what</span> <span style=color:#1f2328>you</span> <span style=color:#1f2328>are</span> <span style=color:#1f2328>doing</span></span></span></code></pre></div></div><p>Note that above I have set the processor and memory limits. This is because I was in this case running on an HPC, and I used those commands to stop MRIQC from hogging all the resources. You may want to skip those inputs if you&rsquo;re running MRIQC locally.</p><p>OR: if you have run all the participants and you just want the group level report, use these mriqc commands instead:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>mriqc /path/to/your/data \ # this is the top level of your data folder
</span></span><span style=display:flex><span>         /path/to/your/data/derivatives \ # where you want mriqc output to be saved. As you are running the group level analysis this folder should be prepopulated with the results of the participant level analysis
</span></span><span style=display:flex><span>         group \ # this tells mriqc to agive you the group report
</span></span><span style=display:flex><span>         -w /path/to/work/directory \ #useful to specify so your home directory definitely does not get clogged
</span></span><span style=display:flex><span>         --nprocs 6 --mem_gb 10000 \ # mriqc can be greedy on the hpc, make sure it is not
</span></span><span style=display:flex><span>         -v # be verbal mriqc, tell me what you are doing</span></span></code></pre></div></div><p>Hit enter, and mriqc should now be merrily working away on your data :)</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6101cf1003c6047c52a1cabcadcb26f0>2.2.4 - PhysIO</h1><div class=lead>Example workflow for the PhysIO Toolbox</div><blockquote><p><em>This tutorial was created by Lars Kasper.</em></p><p>Github: @mrikasper</p><p>Twitter: @mrikasper</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=origin>Origin</h2><p>The PhysIO Toolbox implements ideas for robust physiological noise modeling in fMRI, outlined in this paper:</p><ol><li>Kasper, L., Bollmann, S., Diaconescu, A.O., Hutton, C., Heinzle, J., Iglesias,
S., Hauser, T.U., Sebold, M., Manjaly, Z.-M., Pruessmann, K.P., Stephan, K.E., 2017.
<em>The PhysIO Toolbox for Modeling Physiological Noise in fMRI Data</em>.
Journal of Neuroscience Methods 276, 56-72. <a href=https://doi.org/10.1016/j.jneumeth.2016.10.019 target=_blank rel=noopener>https://doi.org/10.1016/j.jneumeth.2016.10.019</a></li></ol><p>PhysIO is part of the open-source <a href=https://translationalneuromodeling.github.io/tapas/ target=_blank rel=noopener>TAPAS Software Package</a> for Translational Neuromodeling and Computational Psychiatry, introduced in the following paper:</p><ol start=2><li>Frässle, S., Aponte, E.A., Bollmann, S., Brodersen, K.H., Do, C.T., Harrison, O.K., Harrison, S.J., Heinzle, J., Iglesias, S., Kasper, L., Lomakina, E.I., Mathys, C., Müller-Schrader, M., Pereira, I., Petzschner, F.H., Raman, S., Schöbi, D., Toussaint, B., Weber, L.A., Yao, Y., Stephan, K.E., 2021. <em>TAPAS: an open-source software package for Translational Neuromodeling and Computational Psychiatry</em>. Frontiers in Psychiatry 12, 857. <a href=https://doi.org/10.3389/fpsyt.2021.680811 target=_blank rel=noopener>https://doi.org/10.3389/fpsyt.2021.680811</a></li></ol><p>Please cite these works if you use PhysIO and see the <a href=https://gitlab.ethz.ch/physio/physio-doc/-/wikis/FAQ#3-how-do-i-cite-physio target=_blank rel=noopener>FAQ</a> for details.</p><p>NeuroDesk offers the possibility of running PhysIO without installing Matlab or requiring a Matlab license. The functionality should be equivalent, though debugging and extending the toolbox, as well as unreleased development features, will only be available in the Matlab version of PhysIO, which is exclusively hosted on the <a href=https://github.com/translationalneuromodeling/tapas target=_blank rel=noopener>TAPAS GitHub</a>.</p><p>More general info about PhysIO besides NeuroDesk usage is found in the <a href=https://github.com/translationalneuromodeling/tapas/tree/master/PhysIO#readme target=_blank rel=noopener>README</a> on GitHub.</p><h2 id=purpose>Purpose</h2><p>The general purpose of the PhysIO toolbox is model-based physiological noise correction of fMRI data using peripheral measures of respiration and cardiac pulsation (respiratory bellows, ECG, pulse oximeter/plethysmograph).</p><p>It incorporates noise models of</p><ul><li>cardiac/respiratory phase (RETROICOR, Glover et al. 2000), as well as</li><li>heart rate variability and respiratory volume per time (cardiac response function, Chang et. al, 2009, respiratory response function, Birn et al. 2006),</li><li>and extended motion models (e.g., censoring/scrubbing)</li></ul><p>While the toolbox is particularly well integrated with SPM via the Batch Editor GUI, its output text files can be incorporated into any major neuroimaging analysis package for nuisance regression, e.g., within a GLM.</p><p>Core design goals for the toolbox were: flexibility, robustness, and quality assurance to enable physiological noise correction for large-scale and multi-center studies.</p><p>Some highlights:</p><ul><li>Robust automatic preprocessing of peripheral recordings via iterative peak detection, validated in noisy data and patients, and extended processing of respiratory data (Harrison et al., 2021)</li><li>Flexible support of peripheral data formats (BIDS, Siemens, Philips, GE, BioPac, HCP, &mldr;) and noise models (RETROICOR, RVHRCOR).</li><li>Fully automated noise correction and performance assessment for group studies.</li><li>Integration in fMRI pre-processing pipelines as SPM Toolbox (Batch Editor GUI).</li></ul><p>The accompanying technical paper about the toolbox concept and methodology can be found at: <a href=https://doi.org/10.1016/j.jneumeth.2016.10.019 target=_blank rel=noopener>https://doi.org/10.1016/j.jneumeth.2016.10.019</a></p><h2 id=download-example-data>Download Example Data</h2><p>The example data should already be present in NeuroDesk in the following folder <code>/opt/spm12</code></p><p>If you cannot find the example data there:</p><ol><li>Download the latest version from the <a href=https://github.com/translationalneuromodeling/tapas/blob/master/misc/log_tapas.txt target=_blank rel=noopener>location mentioned in the TAPAS distribution</a><ul><li>e.g., <a href=https://www.tapas.tnu-zurich.com/examples_v5.0.0.zip target=_blank rel=noopener>https://www.tapas.tnu-zurich.com/examples_v5.0.0.zip</a></li></ul></li><li>Follow the instructions for copying your own data in the next section</li></ol><h2 id=copy-your-own-data>Copy your own data</h2><ul><li>On Windows, the folder <code>C:\neurodesktop-storage</code> should have been automatically created when starting NeuroDesk</li><li>This is your direct link to the NeuroDesk environment, and anything you put in there should end up within the NeuroDesk desktop in <code>/neurodesktop-storage/</code> and on your desktop under <code>storage</code></li></ul><h2 id=example-running-physio-in-the-gui>Example: Running PhysIO in the GUI</h2><ol><li>Open the PhysIO GUI (Neurodesk -> Functional Imaging -> physio -> physioGUI r7771, see screenshot:</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/physio/physio_screenshot1.jpg alt="PhysIO GUI in NeuroDesk" title=physio_screenshot></p><ol start=2><li>SPM should automatically open up (might take a while). Select &lsquo;fMRI&rsquo; from the modality selection screen.</li><li>Press the &ldquo;Batch Editor&rdquo; button (see screenshot with open Batch Editor, red highlights)</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/physio/physio_screenshot2.jpg alt="NeuroDesk with SPM Batch Editor PhysIO" title=physio_screenshot2></p><pre><code>- NB: If you later want to create a new PhysIO batch with all parameters, from scratch or explore the options, select from the Batch Editor Menu top row, SPM -&gt; Tools -&gt; TAPAS PhysIO Toolbox (see screenshot, read highlights)
</code></pre><ol start=4><li>For now, load an existing example (or previously created SPM Batch File) as follows: It is most convenient to change the working directory of SPM to the location of the physiological logfiles<ul><li>In the Batch Editor GUI, lowest row, choose &lsquo;CD&rsquo; from the &lsquo;Utils..&rsquo; dropdown menu</li><li>Navigate to any of the example folders, e.g., <code>/opt/spm12/examples/Philips/ECG3T/</code> and select it</li><li>NB: you can skip this part, if you later manually update all input files in the Batch Editor window (resp/cardiac/scan timing and realignment parameter file further down)</li><li>Any other example should also work the same way, just CD to its folder before the next step</li></ul></li><li>Select File -> Load Batch from the top row menu of the Batch Editor window<ul><li>make sure you select the matlab batch file <code>*_spm_job.&lt;m|mat></code>, (e.g., <code>philips_ecg3t_spm_job.m</code> and <code>philips_ecg3t_spm_job.mat</code> are identical, either is fine), but not the script.</li></ul></li><li>Press The green &ldquo;Play&rdquo; button in the top icon menu row of the Batch Editor Window</li><li>Several output figures should appear, with the last being a grayscale plot of the nuisance regressor design matrix</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/physio/physio_screenshot3.jpg alt="Output Nuisance Regressor Matrix PhysIO" title=physio_screenshot3></p><ol start=8><li>Congratulations, your first successful physiological noise model has been created! If you don&rsquo;t see the mentioned figure, chances are certain input files were not found (e.g., wrong file location specified). You can always check the text output in the &ldquo;bash&rdquo; window associated with the SPM window for any error messages.</li></ol><h2 id=further-info-on-physio>Further Info on PhysIO</h2><p>Please check out the <a href=https://github.com/translationalneuromodeling/tapas/tree/master/PhysIO#readme target=_blank rel=noopener>README</a> and <a href=https://gitlab.ethz.ch/physio/physio-doc/-/wikis/FAQ target=_blank rel=noopener>FAQ</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-cfcb6a6641bb38f280f08239d3a4d832>2.2.5 - A batch scripting example for PhysIO toolbox</h1><div class=lead>Follow this tutorial as an example of how to batch script for the PhysIO toolbox using Neurodesk.</div><blockquote><p><em>This tutorial was created by Kelly G. Garner.</em></p><p>Github: @kel-github</p><p>Twitter: @garner_theory</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>This tutorial walks through 1 way to batch script the use of the PhysIO toolbox with Neurodesk.
The goal is to use the toolbox to generate physiological regressors to use when modelling fMRI data.
The output format of the regressor files are directly compatible for use with SPM, and can be adapted to fit the specifications of other toolboxes.<p></p><h1 id=getting-started>Getting started</h1><p>This tutorial assumes the following:</p><ol><li>Your data are (largely) in <a href=https://bids.neuroimaging.io/ target=_blank rel=noopener>BIDS format</a></li><li>That you have converted your .zip files containing physiological data to .log files. For example, if you&rsquo;re using a CMRR multi-band sequence, then you can use <a href=https://github.com/CMRR-C2P/MB/blob/master/readCMRRPhysio.m target=_blank rel=noopener>this function</a></li><li>That your .log files are in the subject derivatives/&mldr;/sub-&mldr;/ses-&mldr;/&lsquo;func&rsquo; folders of aforementioned BIDs structured data</li><li>That you have a file that contains the motion regressors you plan to use in your GLM. I&rsquo;ll talk below a bit about what I did with the output given by fmriprep (e.g. &mldr;_desc-confounds_timeseries.tsv&rsquo;)</li><li>That you can use SPM12 and the PhysIO GUI to initialise your batch code</li></ol><p>NB. You can see the code generated from this tutorial <a href=https://github.com/garner-code/imaging_cert_value_7T_pipeline/tree/master/physiol_regress target=_blank rel=noopener>here</a><p></p><h1 id=1-generate-an-example-script-for-batching>1. Generate an example script for batching</h1><p>First you will create an example batch script that is specific to one of your participants. To achieve this I downloaded locally the relevant &lsquo;.log&rsquo; files for one participant, as well as the &lsquo;&mldr;desc-confounds_timeseries.tsv&rsquo; output for fmriprep for each run. PhysIO is nice in that it will append the regressors from your physiological data to your movement parameters, so that you have a single file of regressors to add to your design matrix in SPM etc (other toolboxes are available).<p></p><p>To work with PhysIO toolbox, your motion parameters need to be in the .txt format as required by SPM.</p><p>I made some simple functions in python that would extract my desired movement regressors and save them to the space separated .txt file as is required by SPM. They can be found <a href=https://github.com/garner-code/imaging_cert_value_7T_pipeline/tree/master/physiol_regress/get_movement_regressors target=_blank rel=noopener>here</a>.</p><p>Once I had my .log files and .txt motion regressors file, I followed the instructions <a href=https://gitlab.ethz.ch/physio/physio-doc/-/wikis/QUICKSTART target=_blank rel=noopener>here</a> to get going with the Batch editor, and used <a href=https://doi.org/10.1016/j.jneumeth.2016.10.019 target=_blank rel=noopener>this paper</a> to aid my understanding of how to complete the fields requested by the Batch editor.</p><p>I wound up with a Batch script for the PhysIO toolbox that looked a little bit like this:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/PhysIO_Batch/PhysIOBatch1.png alt=PhysIOBatch1 title=PhysIOBatch1></p><h1 id=2-generalise-the-script-for-use-with-any-participant>2. Generalise the script for use with any participant</h1><p>Now that you have an example script that contains the specific details for a single participant, you are ready to generalise this code so that you can run it for any participant you choose. I decided to do this by doing the following:</p><ul><li>First I generate an &lsquo;info&rsquo; structure for each participant. This is a structure saved as a matfile for each participant under &lsquo;derivatives&rsquo;, in the relevant sub-z/ses-y/func/ folder. This structure contains the subject specific details that PhysIO needs to know to run. Thus I wrote a matlab function that saves a structure called info with the following fields:</li></ul><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Matlab data-lang=Matlab><span style=display:flex><span><span style=color:#57606a>% -- outputs: a matfile containing a structure called info with the</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% following fields:</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- sub_num = subject number: [string] of form &#39;01&#39; &#39;11&#39; or &#39;111&#39;</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- sess = session number: [integer] e.g. 2</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- nrun = [integer] number of runs for that participant</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- nscans = number of scans (volumes) in the design matrix for each</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    run [1, nrun]</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- cardiac_files = a cell of the cardiac files for that participant</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    (1,n = nrun) - attained by using extractCMRRPhysio()</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- respiration_files = same as above but for the resp files - attained by using extractCMRRPhysio()</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- scan_timing = info file from Siemens - attained by using extractCMRRPhysio()</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    -- movement = a cell of the movement regressor files for that</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%    participant (.txt, formatted for SPM)</span></span></span></code></pre></div></div><p>To see the functions that produce this information, you can go to this <a href=https://github.com/garner-code/imaging_cert_value_7T_pipeline/tree/master/physiol_regress target=_blank rel=noopener>repo here</a></p><ul><li>Next I amended the batch script to load a given participant&rsquo;s info file and to retrieve this information for the required fields in the batch. The batch script winds up looking like this:</li></ul><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Matlab data-lang=Matlab><span style=display:flex><span><span style=color:#57606a>%% written by K. Garner, 2022</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% uses batch info:</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%-----------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% Job saved on 17-Aug-2021 10:35:05 by cfg_util (rev $Rev: 7345 $)</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% spm SPM - SPM12 (7771)</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% cfg_basicio BasicIO - Unknown</span>
</span></span><span style=display:flex><span><span style=color:#57606a>%-----------------------------------------------------------------------</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% load participant info, and print into the appropriate batch fields below</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% before running spm jobman</span>
</span></span><span style=display:flex><span><span style=color:#57606a>% assumes data is in BIDS format</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>%% load participant info</span>
</span></span><span style=display:flex><span>sub <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;01&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>dat_path <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;/file/path/to/top-level/of-your-derivatives-fmriprep/folder&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>task <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;attlearn&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>load<span style=color:#1f2328>(</span>fullfile<span style=color:#1f2328>(</span>dat_path<span style=color:#1f2328>,</span> sprintf<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;sub-%s&#39;</span><span style=color:#1f2328>,</span> sub<span style=color:#1f2328>),</span> <span style=color:#0a3069>&#39;ses-02&#39;</span><span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;func&#39;</span><span style=color:#1f2328>,</span> <span style=color:#57606a>...</span>
</span></span><span style=display:flex><span>              sprintf<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;sub-%s_ses-02_task-%s_desc-physioinfo&#39;</span><span style=color:#1f2328>,</span> sub<span style=color:#1f2328>,</span> task<span style=color:#1f2328>)))</span>
</span></span><span style=display:flex><span>          
</span></span><span style=display:flex><span><span style=color:#57606a>% set variables</span>
</span></span><span style=display:flex><span>nrun <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>nrun<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>nscans <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>nscans<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>cardiac_files <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>cardiac_files<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>respiration_files <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>respiration_files<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>scan_timing <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>movement <span style=color:#1f2328>=</span> info<span style=color:#1f2328>.</span>movement<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>          
</span></span><span style=display:flex><span><span style=color:#57606a>%% initialise spm</span>
</span></span><span style=display:flex><span>spm_jobman<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;initcfg&#39;</span><span style=color:#1f2328>);</span> <span style=color:#57606a>% check this for later</span>
</span></span><span style=display:flex><span>spm<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;defaults&#39;</span><span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;FMRI&#39;</span><span style=color:#1f2328>);</span>
</span></span><span style=display:flex><span>          
</span></span><span style=display:flex><span><span style=color:#57606a>%% run through runs, print info and run </span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#cf222e>for</span> irun <span style=color:#1f2328>=</span> <span style=color:#0550ae>1</span><span style=color:#1f2328>:</span>nrun
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    clear matlabbatch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>save_dir <span style=color:#1f2328>=</span> cellstr<span style=color:#1f2328>(</span>fullfile<span style=color:#1f2328>(</span>dat_path<span style=color:#1f2328>,</span> sprintf<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;sub-%s&#39;</span><span style=color:#1f2328>,</span> sub<span style=color:#1f2328>),</span> <span style=color:#0a3069>&#39;ses-02&#39;</span><span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;func&#39;</span><span style=color:#1f2328>));</span> <span style=color:#57606a>% 1</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>vendor <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;Siemens_Tics&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>cardiac <span style=color:#1f2328>=</span> cardiac_files<span style=color:#1f2328>(</span>irun<span style=color:#1f2328>);</span> <span style=color:#57606a>% 2</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>respiration <span style=color:#1f2328>=</span> respiration_files<span style=color:#1f2328>(</span>irun<span style=color:#1f2328>);</span> <span style=color:#57606a>% 3</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>scan_timing <span style=color:#1f2328>=</span> scan_timing<span style=color:#1f2328>(</span>irun<span style=color:#1f2328>);</span> <span style=color:#57606a>% 4</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>sampling_interval <span style=color:#1f2328>=</span> <span style=color:#1f2328>[];</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>relative_start_acquisition <span style=color:#1f2328>=</span> <span style=color:#0550ae>0</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>log_files<span style=color:#1f2328>.</span>align_scan <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;last&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>Nslices <span style=color:#1f2328>=</span> <span style=color:#0550ae>81</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>NslicesPerBeat <span style=color:#1f2328>=</span> <span style=color:#1f2328>[];</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>TR <span style=color:#1f2328>=</span> <span style=color:#0550ae>1.51</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>Ndummies <span style=color:#1f2328>=</span> <span style=color:#0550ae>0</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>Nscans <span style=color:#1f2328>=</span> nscans<span style=color:#1f2328>(</span>irun<span style=color:#1f2328>);</span> <span style=color:#57606a>% 5</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>onset_slice <span style=color:#1f2328>=</span> <span style=color:#0550ae>1</span><span style=color:#1f2328>;</span> 
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>time_slice_to_slice <span style=color:#1f2328>=</span> <span style=color:#1f2328>[];</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sqpar<span style=color:#1f2328>.</span>Nprep <span style=color:#1f2328>=</span> <span style=color:#1f2328>[];</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>scan_timing<span style=color:#1f2328>.</span>sync<span style=color:#1f2328>.</span>nominal <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>modality <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;PPU&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>filter<span style=color:#1f2328>.</span>no <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>initial_cpulse_select<span style=color:#1f2328>.</span>auto_template<span style=color:#1f2328>.</span>min <span style=color:#1f2328>=</span> <span style=color:#0550ae>0.4</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>initial_cpulse_select<span style=color:#1f2328>.</span>auto_template<span style=color:#1f2328>.</span>file <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;initial_cpulse_kRpeakfile.mat&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>initial_cpulse_select<span style=color:#1f2328>.</span>auto_template<span style=color:#1f2328>.</span>max_heart_rate_bpm <span style=color:#1f2328>=</span> <span style=color:#0550ae>90</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>cardiac<span style=color:#1f2328>.</span>posthoc_cpulse_select<span style=color:#1f2328>.</span>off <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>respiratory<span style=color:#1f2328>.</span>filter<span style=color:#1f2328>.</span>passband <span style=color:#1f2328>=</span> <span style=color:#1f2328>[</span><span style=color:#0550ae>0.01</span> <span style=color:#0550ae>2</span><span style=color:#1f2328>];</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>preproc<span style=color:#1f2328>.</span>respiratory<span style=color:#1f2328>.</span>despike <span style=color:#1f2328>=</span> true<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>output_multiple_regressors <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;mregress.txt&#39;</span><span style=color:#1f2328>;</span> 
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>output_physio <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;physio&#39;</span><span style=color:#1f2328>;</span> 
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>orthogonalise <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;none&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>censor_unreliable_recording_intervals <span style=color:#1f2328>=</span> true<span style=color:#1f2328>;</span> <span style=color:#57606a>%false; </span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>retroicor<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>order<span style=color:#1f2328>.</span>c <span style=color:#1f2328>=</span> <span style=color:#0550ae>3</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>retroicor<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>order<span style=color:#1f2328>.</span>r <span style=color:#1f2328>=</span> <span style=color:#0550ae>4</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>retroicor<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>order<span style=color:#1f2328>.</span>cr <span style=color:#1f2328>=</span> <span style=color:#0550ae>1</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>rvt<span style=color:#1f2328>.</span>no <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>hrv<span style=color:#1f2328>.</span>no <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>noise_rois<span style=color:#1f2328>.</span>no <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>movement<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>file_realignment_parameters <span style=color:#1f2328>=</span> <span style=color:#1f2328>{</span>fullfile<span style=color:#1f2328>(</span>dat_path<span style=color:#1f2328>,</span> sprintf<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;sub-%s&#39;</span><span style=color:#1f2328>,</span> sub<span style=color:#1f2328>),</span> <span style=color:#0a3069>&#39;ses-02&#39;</span><span style=color:#1f2328>,</span> <span style=color:#0a3069>&#39;func&#39;</span><span style=color:#1f2328>,</span> sprintf<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;sub-%s_ses-02_task-%s_run-%d_desc-motion_timeseries.txt&#39;</span><span style=color:#1f2328>,</span> sub<span style=color:#1f2328>,</span> task<span style=color:#1f2328>,</span> irun<span style=color:#1f2328>))};</span> <span style=color:#57606a>%8</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>movement<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>order <span style=color:#1f2328>=</span> <span style=color:#0550ae>6</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>movement<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>censoring_method <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;FD&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>movement<span style=color:#1f2328>.</span>yes<span style=color:#1f2328>.</span>censoring_threshold <span style=color:#1f2328>=</span> <span style=color:#0550ae>0.5</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>model<span style=color:#1f2328>.</span>other<span style=color:#1f2328>.</span>no <span style=color:#1f2328>=</span> struct<span style=color:#1f2328>([]);</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>verbose<span style=color:#1f2328>.</span>level <span style=color:#1f2328>=</span> <span style=color:#0550ae>2</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>verbose<span style=color:#1f2328>.</span>fig_output_file <span style=color:#1f2328>=</span> <span style=color:#0a3069>&#39;&#39;</span><span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    matlabbatch<span style=color:#1f2328>{</span><span style=color:#0550ae>1</span><span style=color:#1f2328>}.</span>spm<span style=color:#1f2328>.</span>tools<span style=color:#1f2328>.</span>physio<span style=color:#1f2328>.</span>verbose<span style=color:#1f2328>.</span>use_tabs <span style=color:#1f2328>=</span> false<span style=color:#1f2328>;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    spm_jobman<span style=color:#1f2328>(</span><span style=color:#0a3069>&#39;run&#39;</span><span style=color:#1f2328>,</span> matlabbatch<span style=color:#1f2328>);</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#cf222e>end</span></span></span></code></pre></div></div><h1 id=3-ready-to-run-on-neurodesk>3. Ready to run on Neurodesk!</h1><p>Now we have a batch script, we&rsquo;re ready to run this on Neurodesk - yay!<p></p><p>First make sure the details at the top of the script are correct. You can see that this script could easily be amended to run multiple subjects.</p><p>On Neurodesk, go to the PhysIO toolbox, but select the command line tool rather than the GUI interface (&lsquo;physio r7771 instead of physioGUI r7771). This will take you to the container for the PhysIO toolbox<p></p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/functional_imaging/PhysIO_Batch/PhysIOBatch2.png alt=PhysIOBatch2 title=PhysIOBatch2></p><p>Now to run your PhysIO batch script, type the command:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>run_spm12.sh /opt/mcr/v99/ batch /your/batch/script/named_something.m</span></span></code></pre></div></div><p>Et Voila! Physiological regressors are now yours - mua ha ha!</p></div><div class=td-content style=page-break-before:always><h1 id=pg-493b8ec839ac173dbb80499ac751df6f>2.2.6 - Statistical Parametric Mapping (SPM)</h1><div class=lead>A tutorial for running a functional MRI analysis in SPM.</div><blockquote><p><em>This tutorial was created by Steffen Bollmann.</em></p><p>Email: <a href=mailto:s.bollmannn@uq.edu.au>s.bollmannn@uq.edu.au</a></p><p>Github: @stebo85</p><p>Twitter: @sbollmann_MRI</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>This tutorial is based on the excellent tutorial from Andy&rsquo;s Brain book: <a href=https://andysbrainbook.readthedocs.io/en/latest/SPM/SPM_Overview.html target=_blank rel=noopener>https://andysbrainbook.readthedocs.io/en/latest/SPM/SPM_Overview.html</a>
Our version here is a shortened and adjusted version for using on the Neurodesk platform.</p><h2 id=download-data>Download data</h2><p>First, let&rsquo;s download the data. We will use this open dataset: <a href=https://openneuro.org/datasets/ds000102/versions/00001/download target=_blank rel=noopener>https://openneuro.org/datasets/ds000102/versions/00001/download</a></p><p>Open a terminal and use datalad to install the dataset:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>cd neurodesktop-storage
</span></span><span style=display:flex><span>datalad install https://github.com/OpenNeuroDatasets/ds000102.git</span></span></code></pre></div></div><img width=839 alt=image src=https://user-images.githubusercontent.com/4021595/197097444-900ad262-fbca-4cac-adea-3c7b67a4ecc5.png><p>We will use subject 08 as an example here, so we use datalad to download sub-08 and since SPM doesn&rsquo;t support compressed files, we need to unpack them:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>cd ds000102
</span></span><span style=display:flex><span>datalad get sub-08/
</span></span><span style=display:flex><span>gunzip sub-08/anat/sub-08_T1w.nii.gz -f
</span></span><span style=display:flex><span>gunzip sub-08/func/sub-08_task-flanker_run-1_bold.nii.gz -f
</span></span><span style=display:flex><span>gunzip sub-08/func/sub-08_task-flanker_run-2_bold.nii.gz -f
</span></span><span style=display:flex><span>chmod a+rw sub-08/ -R</span></span></code></pre></div></div><p>The task used is described here: <a href=https://andysbrainbook.readthedocs.io/en/latest/SPM/SPM_Short_Course/SPM_02_Flanker.html target=_blank rel=noopener>https://andysbrainbook.readthedocs.io/en/latest/SPM/SPM_Short_Course/SPM_02_Flanker.html</a></p><h2 id=starting-spm-and-visualizing-the-data>Starting SPM and visualizing the data</h2><p>Start spm12GUI from the Application Menu:
<img width=727 alt=image src=https://user-images.githubusercontent.com/4021595/197098330-3c6611a1-8bbb-49da-b6fb-3752452322cc.png></p><p>When the SPM menu loaded, click on fMRI and the full SPM interface should open up:
<img width=1039 alt=image src=https://user-images.githubusercontent.com/4021595/197098528-aba8f46c-d837-4de5-80c5-07056b784c46.png></p><p>For convenience let&rsquo;s change our default directory to our example subject. Click on <code>Utils</code> and select <code>CD</code>:
<img width=404 alt=image src=https://user-images.githubusercontent.com/4021595/197101928-1bdf67a4-8945-43aa-8df3-877af03bf677.png></p><p>Then navigate to sub-08 and select the directory in the right browser window:
<img width=508 alt=image src=https://user-images.githubusercontent.com/4021595/197102015-2f646e54-0626-4139-b9ac-2ad2a77a2ab6.png></p><p>Now let&rsquo;s visualize the anatomical T1 scan of subject 08 by clicking on Display and navigating and selecting the anatomical scan:
<img width=743 alt=image src=https://user-images.githubusercontent.com/4021595/197100690-b8e7a0b8-6c0b-47fc-8c5f-46f317396361.png></p><img width=1041 alt=image src=https://user-images.githubusercontent.com/4021595/197100737-02fdc59e-94df-4895-b756-fc78e5365cfd.png><p>Now let&rsquo;s look at the functional scans. Use CheckReg and open run-01. Then right click and <code>Browse ...</code>. Then set frames to 1:146 and right click <code>Select All</code></p><img width=506 alt=image src=https://user-images.githubusercontent.com/4021595/197101637-dc486f27-083a-4849-a5af-34666a21e7a4.png><p>Now we get a slider viewer and we can investigate all functional scans:
<img width=609 alt=image src=https://user-images.githubusercontent.com/4021595/197102121-07f1b9c1-3222-4c7c-ad03-eb41e1294460.png></p><p>Let&rsquo;s check the alignment between the anatomical and the functional scans - use CheckReg and open the anatomical and the functional scan. They shouldn&rsquo;t align yet, because we haven&rsquo;t done any preprocessing yet:
<img width=1045 alt=image src=https://user-images.githubusercontent.com/4021595/197103016-509387f1-4d7e-4237-b745-ae7e837dba11.png></p><h2 id=preprocessing-the-data>Preprocessing the data</h2><h3 id=realignment>Realignment</h3><p>Select <code>Realign (Est & Reslice)</code> from the SPM Menu (the third option):
<img width=1121 alt=image src=https://user-images.githubusercontent.com/4021595/197304865-3560f16d-2950-48f4-9b19-b60f63737dc4.png></p><p>Then select the functional run (important: Select frames from 1:146 again!) and leave everything else as Defaults. Then hit run:
<img width=1120 alt=image src=https://user-images.githubusercontent.com/4021595/197304966-61159670-71ef-4542-996f-f88dab8bc1d4.png></p><p>As an output we should see the realignment parameters:
<img width=623 alt=image src=https://user-images.githubusercontent.com/4021595/197106717-0850bb27-cb72-48b1-a532-90910e3267d4.png></p><h3 id=slice-timing-correction>Slice timing correction</h3><p>Click on <code>Slice timing</code> in the SPM menu to bring up the Slice Timing section in the batch editor:
<img width=1115 alt=image src=https://user-images.githubusercontent.com/4021595/197303610-f0e989dc-8646-4c97-ae67-ac5a6b07d3e1.png></p><p>Select the realigned images (use filter <code>rsub</code> and Frames 1:146) and then enter the parameters:</p><ul><li>Number of Slices = 40</li><li>TR = 2</li><li>TA = 1.95</li><li>Slice order = [1:2:40 2:2:40]</li><li>Reference Slice = 1</li></ul><img width=697 alt=image src=https://user-images.githubusercontent.com/4021595/197303803-36496c19-66fe-46c9-9f7b-c80973f51bee.png><h3 id=coregistration>Coregistration</h3><p>Now, we coregister the functional scans and the anatomical scan.</p><p>Click on <code>Coregister (Estimate & Reslice)</code> (the third option) in the SPM menu to bring up the batch editor:
<img width=1119 alt=image src=https://user-images.githubusercontent.com/4021595/197304758-19293222-3256-4a32-8901-6741522e28ea.png></p><p>Use the Mean image as the reference and the T1 scan as the source image and hit Play:
<img width=697 alt=image src=https://user-images.githubusercontent.com/4021595/197305284-f57af4c3-cccc-4f6b-b138-8fbad9d6d51e.png></p><p>Let&rsquo;s use CheckReg again and overlay a Contour (Right Click -> Contour -> Display onto -> all) to check the coregistration between the images:
<img width=621 alt=image src=https://user-images.githubusercontent.com/4021595/197305422-8798294f-50ae-4207-b014-9c2f416a6721.png></p><h3 id=segmentation>Segmentation</h3><p>Click the <code>Segmentation</code> button in the SPM menu:
<img width=697 alt=image src=https://user-images.githubusercontent.com/4021595/197305608-08c0de6a-faf8-4ae9-ab07-664ce84df586.png></p><p>Then change the following settings:</p><ul><li>Volumes = our coregistered anatomical scan rsub-08-T1w.nii</li><li>Save Bias Corrected = Save Bias Correced</li><li>Deformation Fields = Forward</li></ul><p>and hit Play again.</p><h3 id=apply-normalization>Apply normalization</h3><p>Select <code>Normalize (Write)</code> from the SPM menu:
<img width=415 alt=image src=https://user-images.githubusercontent.com/4021595/197305894-36020b36-5e0f-4b06-8e8c-015b7e3b0ba7.png></p><p>For the Deformation Field select the y_rsub-08 file we created in the last step and for the Images to Write select the arsub-08 functional images (Filter ^ar and Frames 1:146):
<img width=515 alt=image src=https://user-images.githubusercontent.com/4021595/197306004-284c02a8-f5b4-4278-9234-3d302e4dccb5.png></p><p>Hit Play again.</p><h3 id=checking-the-normalization>Checking the normalization</h3><p>Use CheckReg to make sure that the functional scans (starting with w to indicate that they were warped: warsub-08) align with the template (found in /opt/spm12/spm12_mcr/spm12/spm12/canonical/avg305T1.nii):</p><img width=621 alt=image src=https://user-images.githubusercontent.com/4021595/197306204-c635b3f5-6e89-40de-9c04-5d94dfec10fc.png><h3 id=smoothing>Smoothing</h3><p>Click the <code>Smooth</code> button in the SPM menu and select the warped functional scans:
<img width=514 alt=image src=https://user-images.githubusercontent.com/4021595/197306354-60ee76e2-73ac-4fe8-8387-038d10580c99.png></p><p>Then click Play.</p><p>You can check the smoothing by using CheckReg again:
<img width=624 alt=image src=https://user-images.githubusercontent.com/4021595/197306424-8c407cd5-7ba9-4ae3-83ee-4fa8ec22e41f.png></p><h2 id=analyzing-the-data>Analyzing the data</h2><p>Click on <code>Specify 1st-level</code> - then set the following options:</p><ul><li>Directory: Select the sub-08 top level directory</li><li>Units for design: Seconds</li><li>Interscan interval: 2</li><li>Data & Design: Click twice on New Subject/Session</li><li>Select the smoothed, warped data from run 1 and run 2 for the two sessions respectively</li><li>Create two Conditions per run and set the following:</li><li>For Run 1:</li><li>Name: Inc</li><li>Onsets (you can copy from here and paste with CTRL-V): 0 10 20 52 88 130 144 174 236 248 260 274</li><li>Durations: 2 (SPM will assume that it&rsquo;s the same for each event)</li><li>Name: Con</li><li>Onsets: 32 42 64 76 102 116 154 164 184 196 208 222</li><li>Durations: 2</li><li>For Run 2:</li><li>Name: Inc</li><li>Onsets: 0 10 52 64 88 150 164 174 184 196 232 260</li><li>Durations: 2</li><li>Name: Con</li><li>Onsets: 20 30 40 76 102 116 130 140 208 220 246 274</li><li>Durations: 2</li></ul><p>When done, click the green Play button.</p><p>We can Review the design by clicking on <code>Review</code> in the SPM menu and selecting the SPM.mat file in the model directory we specified earlier and it should look like this:
<img width=626 alt=image src=https://user-images.githubusercontent.com/4021595/197309811-da1fb6d2-1eb3-4ed8-9fe7-560292b645a4.png></p><h3 id=estimating-the-model>Estimating the model</h3><p>Click on <code>Estimate</code> in the SPM menu and select the SPM.mat file, then hit the green Play button.</p><h3 id=inference>Inference</h3><p>Now open the <code>Results</code> section and select the SPM.mat file again. Then we can test our hypotheses:</p><p>Define a new contrast as:</p><ul><li>Name: Incongruent-Congruent</li><li>Contrast weights vector: 0.5 -0.5 0.5 -0.5</li></ul><img width=518 alt=image src=https://user-images.githubusercontent.com/4021595/197309988-5f09952a-fc3d-4a8b-9797-22dbdd165e12.png><p>Then we can view the results. Set the following options:</p><ul><li>masking: none”</li><li>p value adjustment to control: Click on “none”, and set the uncorrected p-value to 0.01.</li><li>extent threshold {voxels}: 10</li></ul><img width=622 alt=image src=https://user-images.githubusercontent.com/4021595/197310053-cde3d7cb-9af1-4a5b-8923-6c26b7b2a5ee.png></div><div class=td-content style=page-break-before:always><h1 id=pg-9169c9f8aa42ef9f7749cbdd72776eea>2.3 - MRI phase Processing</h1><div class=lead>Tutorials about processing MRI phase</div></div><div class=td-content><h1 id=pg-a145cdccb601a4a078fd1a504694dfb4>2.3.1 - Quantitative Susceptibility Mapping</h1><div class=lead>Example workflow for Quantitative Susceptibility Mapping</div><blockquote><p><em>This tutorial was created by Steffen Bollmann and Ashley Stewart.</em></p><p>Github: <a href=https://github.com/stebo85 target=_blank rel=noopener>@stebo85</a>; <a href=https://github.com/astewartau target=_blank rel=noopener>@astewartau</a>
Web: <a href=https://mri.sbollmann.net/ target=_blank rel=noopener>mri.sbollmann.net</a>
Twitter: <a href=https://twitter.com/sbollmann_MRI target=_blank rel=noopener>@sbollmann_MRI</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><blockquote><p><em>An example notebook can be found here:</em>
<a href=https://neurodesk.org/example-notebooks/structural_imaging/qsmxt_example.html target=_blank rel=noopener>https://neurodesk.org/example-notebooks/structural_imaging/qsmxt_example.html</a></p></blockquote><p>Please see the above example notebook which provides a detailed QSM tutorial using QSMxT.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b5ea0caa988918c2ca542947f565b20a>2.3.2 - SWI</h1><div class=lead>Example workflow for SWI processing</div><blockquote><p><em>This tutorial was created by Steffen Bollmann.</em></p><p>Github: <a href=https://github.com/stebo85 target=_blank rel=noopener>@stebo85</a>
Web: <a href=https://mri.sbollmann.net/ target=_blank rel=noopener>mri.sbollmann.net</a>
Twitter: <a href=https://twitter.com/sbollmann_MRI target=_blank rel=noopener>@sbollmann_MRI</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=download-demo-data>Download demo data</h2><p>Open a terminal and run:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>pip install osfclient
</span></span><span style=display:flex><span>cd /neurodesktop-storage/
</span></span><span style=display:flex><span>osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/</span></span></code></pre></div></div><p>Open the CLEARSWI tool from the application menu:</p><p>paste this julia script in a julia file and execute:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>cd /neurodesktop-storage/
</span></span><span style=display:flex><span>vi clearswi.jl</span></span></code></pre></div></div><p>hit a or i and then paste this:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>using CLEARSWI
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>TEs = [20] 
</span></span><span style=display:flex><span>nifti_folder = &#34;/neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat&#34;
</span></span><span style=display:flex><span>magfile = joinpath(nifti_folder, &#34;sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz&#34;)
</span></span><span style=display:flex><span>phasefile = joinpath(nifti_folder, &#34;sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz&#34;) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mag = readmag(magfile);
</span></span><span style=display:flex><span>phase = readphase(phasefile);
</span></span><span style=display:flex><span>data = Data(mag, phase, mag.header, TEs);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>swi = calculateSWI(data);
</span></span><span style=display:flex><span># mip = createIntensityProjection(swi, minimum); # minimum intensity projection, other Julia functions can be used instead of minimum
</span></span><span style=display:flex><span>mip = createMIP(swi); # shorthand for createIntensityProjection(swi, minimum)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>savenii(swi, &#34;/neurodesktop-storage/swi-demo/swi.nii&#34;; header=mag.header) 
</span></span><span style=display:flex><span>savenii(mip, &#34;/neurodesktop-storage/swi-demo/mip.nii&#34;; header=mag.header)</span></span></code></pre></div></div><p>hit SHIFT-Z-Z and run:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>julia clearswi.jl</span></span></code></pre></div></div><p>Open ITK snap from the Visualization Application&rsquo;s menu and inspect the results (the outputs are in swi-demo/swi.nii and mip.nii)
<img src=https://user-images.githubusercontent.com/4021595/137708852-6b7dd2c7-3e6f-42fd-88e6-06afe87a72a9.png alt=image></p></div><div class=td-content style=page-break-before:always><h1 id=pg-6599b665ff2932debfa8480297a31761>2.3.3 - Unwrapping</h1><div class=lead>MRI Phase Unwrapping</div><blockquote><p><em>This tutorial was created by Steffen Bollmann.</em></p><p>Github: <a href=https://github.com/stebo85 target=_blank rel=noopener>@stebo85</a>
Web: <a href=https://mri.sbollmann.net/ target=_blank rel=noopener>mri.sbollmann.net</a>
Twitter: <a href=https://twitter.com/sbollmann_MRI target=_blank rel=noopener>@sbollmann_MRI</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=download-demo-data>Download demo data</h2><p>Open a terminal and run:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>pip install osfclient
</span></span><span style=display:flex><span>cd /neurodesktop-storage/
</span></span><span style=display:flex><span>osf -p ru43c fetch 01_bids.zip /neurodesktop-storage/swi-demo/01_bids.zip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>unzip /neurodesktop-storage/swi-demo/01_bids.zip -d /neurodesktop-storage/swi-demo/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mkdir /neurodesktop-storage/romeo-demo/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsmPH00_run-1_phase.nii.gz /neurodesktop-storage/romeo-demo/phase.nii.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cp /neurodesktop-storage/swi-demo/01_bids/sub-170705134431std1312211075243167001/ses-1/anat/sub-170705134431std1312211075243167001_ses-1_acq-qsm_run-1_magnitude.nii.gz /neurodesktop-storage/romeo-demo/mag.nii.gz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>gunzip /neurodesktop-storage/romeo-demo/mag.nii.gz
</span></span><span style=display:flex><span>gunzip /neurodesktop-storage/romeo-demo/phase.nii.gz</span></span></code></pre></div></div><h3 id=using-romeo-for-phase-unwrapping>Using ROMEO for phase unwrapping</h3><p>Open the ROMEO tool from the application menu and run:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>romeo -p /neurodesktop-storage/romeo-demo/phase.nii -m /neurodesktop-storage/romeo-demo/mag.nii -k nomask -o /neurodesktop-storage/romeo-demo/</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/phase_processing/unwrapping/romeo.PNG alt=Romeo title=Romeo></p></div><div class=td-content style=page-break-before:always><h1 id=pg-fab12cde1b1cb47d8de34f831eb4e7bb>2.4 - Multimodal Imaging</h1><div class=lead>Tutorials about processing multimodal data (e.g. functional MRI, diffusion, MEG/EEG)</div></div><div class=td-content><h1 id=pg-275f1d8c52f90b8c9042ba260fb946e0>2.4.1 - Using MFCSC</h1><div class=lead>A tutorial for using MFCSC to integrate connectomes from different modalities</div><blockquote><p><em>This tutorial was created by Oren Civier.</em></p><p>Github: [@civier]
Email: <a href=mailto:orenciv@gmail.com>orenciv@gmail.com</a></p></blockquote><hr><p>More details on MFCSC and this tutorial can be found in the following paper:</p><blockquote><p>Civier O, Sourty M, Calamante F (2023) MFCSC: Novel method to calculate mismatch between functional and structural brain connectomes, and its application for detecting hemispheric functional specialisations. Scientific Reports
<a href=https://doi.org/10.1038/s41598-022-17213-z target=_blank rel=noopener>https://doi.org/10.1038/s41598-022-17213-z</a></p></blockquote><p>In short, MFCSC calculates the mismatch between connectomes generated from different imaging modalities. It does it by normalising the connectomes to a common space calculated at group level, and taking into account the role of indirect connectivity in shaping the functional connectomes.</p><p><strong>TUTORIAL FOR CONNECTOMES FROM fMRI AND dMRI</strong></p><ol><li><p>Download the &ldquo;input&rdquo; folder from the OSF repository (<a href=https://osf.io/d7j9n/files/osfstorage target=_blank rel=noopener>https://osf.io/d7j9n/files/osfstorage</a>)</p></li><li><p>Launch mfcsc from either &ldquo;Neurodesk&rdquo;&ndash;>&ldquo;Diffusion Imaging &ndash;> mfsc &ndash;> mfcsc 1.1&rdquo; or &ldquo;Neurodesk&rdquo;&ndash;>&ldquo;Functional Imaging &ndash;> mfcsc &ndash;> mfcsc 1.1&rdquo; in the start menu.</p></li><li><p>Run the following command with <strong>input</strong> being the directory where the input data was downloaded to, and <strong>outputdir</strong> being the directory where the output should be written to:</p></li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>    mfcsc input/FC_SC_list.txt input/FC input/SC outputdir</span></span></code></pre></div></div><ol start=4><li>After MFCSC finishes running, the content of <strong>outputdir</strong> should be identical to the &ldquo;output&rdquo; folder in the OSF repository (<a href=https://osf.io/d7j9n/files/osfstorage target=_blank rel=noopener>https://osf.io/d7j9n/files/osfstorage</a>)
It contains connectomes that encode the mismatch between functional and structural connectivity (mFCSC) for every connection.</li></ol><p><strong>TUTORIAL FOR CONNECTOMES FROM MEG AND dMRI</strong></p><ol><li><p>Use the MEG connectivity tutorial to generate functional connectomes from your MEG data using MNE tools on Neurodesk (Tutorial in progress: <a href=https://github.com/benmslade/neurodesk.github.io/blob/main/content/en/tutorials/electrophysiology/meg_connectivity.md target=_blank rel=noopener>https://github.com/benmslade/neurodesk.github.io/blob/main/content/en/tutorials/electrophysiology/meg_connectivity.md</a>)</p></li><li><p>Use the structul connectivity tutorial to generate structural connectomes from your dMRI data using MRtrix tools on Neurodesk (<a href=https://neurodesk.org/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/ target=_blank rel=noopener>https://neurodesk.org/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/</a>)</p></li><li><p>Launch mfcsc from either &ldquo;Neurodesk&rdquo;&ndash;>&ldquo;Diffusion Imaging &ndash;> mfsc &ndash;> mfcsc 1.1&rdquo; or &ldquo;Neurodesk&rdquo;&ndash;>&ldquo;Functional Imaging &ndash;> mfcsc &ndash;> mfcsc 1.1&rdquo; in the start menu.</p></li><li><p>Copy the MEG connectomes into input/MEG and the structural connectomes into input/SC</p></li><li><p>Create an input/MEG_SC_list.txt file that lists the pairing between MEG and structural connectomes</p></li><li><p>Run the following command with <strong>input</strong> being the directory where the input data was downloaded to, and <strong>outputdir</strong> being the directory where the output should be written to:</p></li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>    mfcsc input/MEG_SC_list.txt input/MEG input/SC outputdir</span></span></code></pre></div></div><ol start=7><li>After MFCSC finishes running, <strong>outputdir</strong> will contains connectomes that encode the mismatch between MEG and structural connectivity (mFCSC) for every connection.</li></ol><hr><p><strong>CITATIONS</strong></p><p>When using MFCSC, authors should cite:</p><blockquote><p>Civier O, Sourty M, Calamante F (2023) MFCSC: Novel method to calculate mismatch between functional and structural brain connectomes, and its application for detecting hemispheric functional specialisations. Scientific Reports
<a href=https://doi.org/10.1038/s41598-022-17213-z target=_blank rel=noopener>https://doi.org/10.1038/s41598-022-17213-z</a></p></blockquote><blockquote><p>Rubinov M, Sporns O (2010) Complex network measures of brain
connectivity: Uses and interpretations. NeuroImage 52:1059-69.</p></blockquote><p>When using the structural connectivity matrices from OSF, authors should cite:</p><blockquote><p>Civier O, Smith RE, Yeh CH, Connelly A, Calamante F (2019) Is removal of weak connections necessary for graph-theoretical analysis of dense weighted structural connectomes from diffusion MRI? NeuroImage <a href=http://doi.org/10.1016/j.neuroimage.2019.02.039 target=_blank rel=noopener>http://doi.org/10.1016/j.neuroimage.2019.02.039</a></p></blockquote><p>&mldr; and include the following acknowledgment:</p><blockquote><p>Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University, St. Louis, MO.</p></blockquote><p>When using the functional connectivity matrices from OSF, authors should cite:</p><blockquote><p>Civier O, Sourty M, Calamante F (2023) MFCSC: Novel method to calculate mismatch between functional and structural brain connectomes, and its application for detecting hemispheric functional specialisations. Scientific Reports <a href=https://doi.org/10.1038/s41598-022-17213-z target=_blank rel=noopener>https://doi.org/10.1038/s41598-022-17213-z</a></p></blockquote><p>&mldr; and include the following acknowledgment:</p><blockquote><p>Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University, St. Louis, MO.</p></blockquote><hr><p><strong>ACKNOWLEDGMENTS</strong></p><p>National Health and Medical Research Council of Australia (grant numbers APP1091593 andAPP1117724)</p><p>Australian Research Council (grant number DP170101815)</p><p>National Imaging Facility (NIF), a National Collaborative Research Infrastructure Strategy (NCRIS) capability at Swinburne Neuroimaging, Swinburne University of Technology.</p><p>Victorian Government’s Operational Infrastructure Support</p><p>Melbourne Bioinformatics at the University of Melbourne (grant number UOM0048)</p><p>Sydney Informatics Hub and the University of Sydney’s high performance computing cluster Artemis</p><p>Australian Electrophysiology Data Analytics PlaTform (AEDAPT); Australian Research Data Commons</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e57a258694345082853a63c13b0f1bee>2.5 - Open Data</h1><div class=lead>Tutorials about publishing and accessing open datasets</div></div><div class=td-content><h1 id=pg-a9cdb907d2653c4a233e2f7954eb198d>2.5.1 - datalad</h1><div class=lead>Using datalad to publish and access open data on OSF</div><blockquote><p><em>This tutorial was created by Steffen Bollmannn.</em></p><p>Github: @stebo85</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>DataLad is an open-source tool to publish and access open datasets. In addition to many open data sources (OpenNeuro, CBRAIN, brainlife.io, CONP, DANDI, Courtois Neuromod, Dataverse, Neurobagel), it can also connect to the Open Science Framework (OSF): <a href=http://osf.io/ target=_blank rel=noopener>http://osf.io/</a></p><h1 id=publish-a-dataset>Publish a dataset</h1><p>First we have to create a DataLad dataset:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>datalad create my_dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># now add files to your project and then add save the files with datalad</span>
</span></span><span style=display:flex><span>datalad save -m <span style=color:#0a3069>&#34;added new files&#34;</span></span></span></code></pre></div></div><p>Now we can create a token on OSF (Account Settings -> Personal access tokens -> Create token) and authenticate:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>datalad osf-credentials</span></span></code></pre></div></div><p>Here is an example how to publish a dataset on the OSF:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># create sibling</span>
</span></span><span style=display:flex><span>datalad create-sibling-osf --title best-study-ever -s osf
</span></span><span style=display:flex><span>git config --global --add datalad.extensions.load next
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># push</span>
</span></span><span style=display:flex><span>datalad push --to osf</span></span></code></pre></div></div><p>The last steps creates a DataLad dataset, which is not easily human readable.</p><p>If you would like to create a human-readable dataset (but without the option of downloading it as a datalad dataset later on):</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># create sibling</span>
</span></span><span style=display:flex><span>datalad create-sibling-osf --title best-study-ever-human-readable --mode exportonly -s osf-export
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git-annex <span style=color:#6639ba>export</span> HEAD --to osf-export-storage</span></span></code></pre></div></div><h1 id=access-a-dataset>Access a dataset</h1><p>To download a dataset from the OSF (if it was uploaded as a DataLad dataset before):</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>datalad clone osf://ehnwz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6639ba>cd</span> ehnwz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># now get the files you want to download:</span>
</span></span><span style=display:flex><span>datalad get .</span></span></code></pre></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-e582735ce6bbb18ef6a0230acdcd54f3>2.5.2 - osfclient</h1><div class=lead>Using osfclient to publish and access open data on OSF</div><blockquote><p><em>This tutorial was created by Steffen Bollmannn.</em></p><p>Github: @stebo85</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>The osfclient is an open-source tool to publish and access open datasets on the Open Science Framework (OSF): <a href=http://osf.io/ target=_blank rel=noopener>http://osf.io/</a></p><h1 id=setup-an-osf-token>Setup an OSF token</h1><p>You can generate an OSF token under your user <a href=https://osf.io/settings/tokens target=_blank rel=noopener>settings</a>. Then, set the OSF token as an environment variable:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span><span style=color:#6639ba>export</span> <span style=color:#953800>OSF_TOKEN</span><span style=color:#0550ae>=</span>YOURTOKEN</span></span></code></pre></div></div><h1 id=publish-a-dataset>Publish a dataset</h1><p>Here is an example how to publish a dataset on the OSF:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span><span style=color:#6639ba>cd</span> /path/to/dataset
</span></span><span style=display:flex><span>osf init
</span></span><span style=display:flex><span><span style=color:#57606a># enter your OSF credentials and project ID</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># now copy your data into the directory, cd into the directory and then run:</span>
</span></span><span style=display:flex><span>osf upload -r ./data osfstorage/data
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># beware, hidden files may need to be deleted</span></span></span></code></pre></div></div><h3 id=note-for-those-who-have-used-orcid-to-create-their-account--log-in>Note for those who have used ORCID to create their account / log in</h3><p>You can still use OSF to upload, but you need to use the TOKEN as the username in osf init (from testing, you don&rsquo;t need to export the OSF_TOKEN variable).
It won&rsquo;t ask you for a password.</p><h3 id=note-on-storage-for-osf>Note on storage for OSF</h3><p>The limits are now 5GB for private repo, 50gb for public repo as of 2025.</p><h1 id=access-a-dataset>Access a dataset</h1><p>To download a dataset from the OSF:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Bash data-lang=Bash><span style=display:flex><span>osf -p PROJECTID_HERE_eg_y5cq9 clone .</span></span></code></pre></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-975f36ee03d553100bb37c702b1a8519>2.6 - Programming</h1><div class=lead>Tutorials about programming with matlab, julia, and others.</div></div><div class=td-content><h1 id=pg-942fa115fd731c2e10fa187f9f0233d7>2.6.1 - Conda environments</h1><div class=lead>A tutorial for setting up your conda environments on Neurodesk.</div><blockquote><p><em>This tutorial was created by Fernanda L. Ribeiro.</em></p><p>Email: <a href=mailto:fernanda.ribeiro@uq.edu.au>fernanda.ribeiro@uq.edu.au</a></p><p>Github: @felenitaribeiro</p><p>Twitter: @NandaRibeiro93</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>This tutorial documents how to create conda environments on Neurodesk.</p><h2 id=condamamba-environment>Conda/Mamba environment</h2><p>The default conda environment is not persistent across sessions, so this means any packages you install in the standard environment will disappear after you restart the Jupyterlab instance. However, you can create your own conda environment, which will be stored in your homedirectory, by following the steps on this page. This method can also be used to install additional kernels, such as an R kernel.</p><ol><li>In a Terminal window, type in:</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/conda/1_terminal.png alt=1_terminal title=1_terminal></p><p>For <em>Python</em>:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mamba create -n myenv ipykernel
</span></span><span style=display:flex><span><span style=color:#57606a>#OR</span>
</span></span><span style=display:flex><span>conda create -n myenv ipykernel</span></span></code></pre></div></div><p>or for <em>R</em>:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mamba create -n r_env r-irkernel
</span></span><span style=display:flex><span><span style=color:#57606a>#OR</span>
</span></span><span style=display:flex><span>conda create -n r_env r-irkernel</span></span></code></pre></div></div><p><strong>Important:</strong> For Python environments, you have to set the ipykernel explicitly or a Python version (like &ldquo;conda create -n myenv python=3.8&rdquo;), since a kernel is required. Alternatively, in case it was forgotten, you can add a kernel with:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda install ipykernel</span></span></code></pre></div></div><ol start=2><li>To check the list of environments you have created, run the following:</li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mamba env list
</span></span><span style=display:flex><span><span style=color:#57606a>#OR</span>
</span></span><span style=display:flex><span>conda env list</span></span></code></pre></div></div><ol start=3><li>To activate your conda environment and install the required packages from a provided txt file, run:
For <em>Python</em>:</li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda activate myenv
</span></span><span style=display:flex><span>pip install -r requirements.txt</span></span></code></pre></div></div><p>or for <em>R</em>:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>conda activate r_env
</span></span><span style=display:flex><span>pip install -r requirements.txt</span></span></code></pre></div></div><ol start=4><li>Given the available environment, when you open a new Launcher tab, there will be a new Notebook option for launching a Jupyter Notebook with that environment active.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/conda/2_env.png alt=2_env title=2_env></p><p>Switching the environment on a Jupyter Notebook is also possible on the top right corner dropdown menu.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/conda/3_notebook.png alt=3_notebook title=3_notebook></p></div><div class=td-content style=page-break-before:always><h1 id=pg-35b213496a18ca6b677b64b947f54bb8>2.6.2 - Matlab</h1><div class=lead>A tutorial for setting up your matlab license on Neurodesk.</div><blockquote><p><em>This tutorial was created by Fernanda L. Ribeiro.</em></p><p>Email: <a href=mailto:fernanda.ribeiro@uq.edu.au>fernanda.ribeiro@uq.edu.au</a></p><p>Github: @felenitaribeiro</p><p>Twitter: @NandaRibeiro93</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>This tutorial documents how to set up your matlab license on Neurodesk.</p><h2 id=matlab-license>Matlab license</h2><ol start=0><li><p>Note: You need your own Matlab license to use Matlab in Neurodesk. You can either login to your matlab account or you can provide an institutional network license server if your neurodesk runs within your institution network and ran reach your license server.</p></li><li><p>a) Institutional network license
run the following command once and replace the address of your license server and the license number</p></li></ol><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir -p /home/jovyan/Downloads <span style=color:#0550ae>&amp;&amp;</span> <span style=color:#6639ba>echo</span> -e <span style=color:#0a3069>&#34;SERVER rtlicense1.university.edu D1234560F6 27007\nUSE_SERVER&#34;</span> &gt; /home/jovyan/Downloads/network.lic</span></span></code></pre></div></div><ol><li>b) Mathworks account: In the application menu, navigate to Neurodesk → Programming → matlab → matlabGUI 2022a</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/0_appmenu.png alt=1_menu title=1_menu></p><ol start=2><li>Select “Activate automatically using the internet” and hit next.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/1_matlabgui.png alt=2_matlabgui title=2_matlabgui></p><p>Then, add your email address and password from your MathWorks account (which you can set up using your university credentials if they provide a license for staff and students).</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/2_login.png alt=2_login title=2_login></p><ol start=3><li>Hit next after you select the appropriate license.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/3_license.png alt=3_license title=3_license></p><ol start=4><li>Do not change the login name and hit next.</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/4_username.png alt=4_username title=4_username></p><ol start=5><li>Hit confirm, and you are all set!</li></ol><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/programming/matlab/5_confirm.png alt=5_confirm title=5_confirm></p><ol start=6><li>To launch the GUI, navigate through the application menu to Neurodesk → Programming → matlab → matlabGUI 2022a</li></ol><h2 id=calling-neurodesk-tools-from-within-matlab>Calling Neurodesk tools from within Matlab</h2><p>You can use Neurodesk software within Matlab by adding the specific Neurodesk container to your execution Path. For the example of adding the FSL package, this can be done as follows in Matlab:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>setenv(&#34;PATH&#34;,getenv(&#34;PATH&#34;) + &#34;:/cvmfs/neurodesk.ardc.edu.au/containers/fsl_6.0.7.4_20231005&#34;);</span></span></code></pre></div></div><p>Now you can, for example, use fslmaths in Matlab scripts:
<img width=1477 alt=image src=https://github.com/NeuroDesk/neurodesk.github.io/assets/4021595/c98957ff-2bbc-4e6e-b7f5-313ed8ce4132></p><p>Let us know if this works well for you, and we would be very keen to hear if there is a better way of integrating the lmod system in Matlab.</p><h2 id=changing-matlab-keyboard-shortcuts>Changing Matlab Keyboard Shortcuts</h2><p>By default, Matlab uses the emacs keyboard shortcuts in Linux, which might not be what most users expect. To change the keyboard shortcuts to a more common pattern, follow the next steps:</p><p>Open the Preferences menu:</p><img width=952 alt=image src=https://github.com/NeuroDesk/neurodesk.github.io/assets/4021595/570c1ab4-2388-4f11-a8b4-939c5438a792><p>Navigate to Keyboard -> Shortcuts and change the active settings from &ldquo;Emacs Default Set&rdquo; to &ldquo;Windows Default Set&rdquo;:</p><img width=656 alt=image src=https://github.com/NeuroDesk/neurodesk.github.io/assets/4021595/59642792-2146-4ede-9bfa-90dffee7e85a></div><div class=td-content style=page-break-before:always><h1 id=pg-3624cd3076e161d1fbbc4bfcc814e38d>2.7 - Reproducibility</h1><div class=lead>Tutorials about performing reproducible analyses in general</div></div><div class=td-content><h1 id=pg-7a7a8485e505bec7f6267a534329dfa7>2.7.1 - Reproducible script execution with DataLad</h1><div class=lead>Using datalad run, you can precisely record results of your analysis scripts.</div><blockquote><p><em>This tutorial was created by Sin Kim.</em></p><p>Github: @kimsin98</p><p>Twitter: @SinKim98</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>In addition to being a convenient method of sharing data, DataLad can also help
you create reproducible analyses by recording how certain result files were
produced (i.e. <em>provenance</em>). This helps others (and you!) easily keep track of
analyses and rerun them.</p><p>This tutorial will assume you know the basics of navigating the terminal. If
you are not familiar with the terminal at all, check the DataLad Handbook&rsquo;s
<a href=http://handbook.datalad.org/en/latest/intro/howto.html target=_blank rel=noopener>brief guide</a>.</p><h2 id=create-a-datalad-project>Create a DataLad project</h2><p>A DataLad <em>dataset</em> can be any collection of files in folders, so it could be
many things including an analysis project. Let&rsquo;s go to the Neurodesktop storage
and create a dataset for some project. Open a terminal and enter these commands:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ cd /storage
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ datalad create -c yoda SomeProject
</span></span><span style=display:flex><span>[INFO   ] Creating a new annex repo at /home/user/Desktop/storage/SomeProject
</span></span><span style=display:flex><span>[INFO   ] Running procedure cfg_yoda
</span></span><span style=display:flex><span>[INFO   ] == Command start (output follows) =====
</span></span><span style=display:flex><span>[INFO   ] == Command exit (modification check follows) =====
</span></span><span style=display:flex><span>create(ok): /home/user/Desktop/storage/SomeProject (dataset)</span></span></code></pre></div></div><div class="alert alert-primary" role=alert><h4 class=alert-heading>yoda?</h4><code>-c yoda</code> option configures the dataset according to
the <a href=http://handbook.datalad.org/en/latest/basics/101-127-yoda.html target=_blank rel=noopener>YODA</a>, a
set of intuitive organizational principles for data analyses that works
especially well with version control.</div><p>Go in the dataset and check its contents.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ cd SomeProject
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ ls
</span></span><span style=display:flex><span>CHANGELOG.md  README.md  code</span></span></code></pre></div></div><h2 id=create-a-script>Create a script</h2><p>One of DataLad&rsquo;s strengths is that it assumes very little about your datasets.
Thus, it can work with any other software on the terminal: Python, R, MATLAB,
AFNI, FSL, FreeSurfer, etc. For this tutorial, we will run the simplest Julia
script.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ ml julia
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cat &gt; code/hello.jl &lt;&lt; EOF
</span></span><span style=display:flex><span>println(&#34;hello neurodesktop&#34;)
</span></span><span style=display:flex><span>EOF</span></span></code></pre></div></div><div class="alert alert-primary" role=alert><h4 class=alert-heading>EOF?</h4>For sake of demonstration, we create the script using
built-in Bash terminal commands only (here document that starts after <code>&lt;&lt; EOF</code>
and ends when you enter <code>EOF</code>), but you may use whatever text editor you are
most comfortable with to create the <code>code/hello.jl</code> file.</div><p>You may want to test (parts of) your script.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ julia code/hello.jl &gt; hello.txt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cat hello.txt
</span></span><span style=display:flex><span>hello neurodesktop</span></span></code></pre></div></div><h2 id=run-and-record>Run and record</h2><p>Before you run your analyses, you should check the dataset for changes and save
or clean them.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ datalad status
</span></span><span style=display:flex><span>untracked: /home/user/Desktop/storage/SomeProject/code/hello.jl (file)
</span></span><span style=display:flex><span>untracked: /home/user/Desktop/storage/SomeProject/hello.txt (file)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ datalad save -m &#39;hello script&#39; code/
</span></span><span style=display:flex><span>add(ok): code/hello.jl (file)
</span></span><span style=display:flex><span>save(ok): . (dataset)
</span></span><span style=display:flex><span>action summary:
</span></span><span style=display:flex><span>  add (ok: 1)
</span></span><span style=display:flex><span>  save (ok: 1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ git clean -i
</span></span><span style=display:flex><span>Would remove the following item:
</span></span><span style=display:flex><span>  hello.txt
</span></span><span style=display:flex><span>*** Commands ***
</span></span><span style=display:flex><span>  1: clean    2: filter by pattern    3: select by numbers    4: ask each   5: quit   6: help
</span></span><span style=display:flex><span>What now&gt; 1
</span></span><span style=display:flex><span>Removing hello.txt</span></span></code></pre></div></div><div class="alert alert-primary" role=alert><h4 class=alert-heading>git</h4><code>git clean</code> is for removing new, untracked files. For
resetting existing, modified files to the last saved version, you would need
<code>git reset --hard</code>.</div><p>When the dataset is clean, we are ready to <code>datalad run</code>!</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ mkdir outputs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ datalad run -m &#39;run hello&#39; -o &#39;outputs/hello.txt&#39; &#39;julia code/hello.jl &gt; outputs/hello.txt&#39;
</span></span><span style=display:flex><span>[INFO   ] == Command start (output follows) =====
</span></span><span style=display:flex><span>[INFO   ] == Command exit (modification check follows) =====
</span></span><span style=display:flex><span>add(ok): outputs/hello.txt (file)
</span></span><span style=display:flex><span>save(ok): . (dataset)</span></span></code></pre></div></div><p>Let&rsquo;s go over each of the arguments:</p><ul><li><code>-m 'run hello'</code>: Human-readable message to record in the dataset log.</li><li><code>-o 'outputs/hello.txt'</code>: Expected output of the script. You can specify
multiple <code>-o</code> arguments and/or use wildcards like <code>'outputs/*'</code>. This script
has no inputs, but you can similarly specify inputs with <code>-i</code>.</li><li><code>'julia ... '</code>: The final argument is the command that DataLad will run.</li></ul><p>Before getting to the exciting part, let&rsquo;s do a quick sanity check.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ cat outputs/hello.txt
</span></span><span style=display:flex><span>hello neurodesktop</span></span></code></pre></div></div><h2 id=view-history-and-rerun>View history and rerun</h2><p>So what&rsquo;s so good about the extra hassle of running scripts with <code>datalad run</code>?
To see that, you will need to pretend you are someone else (or you of future!)
and install the dataset somewhere else. Note that <code>-s</code> argument is probably a
URL if you were really someone else.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ cd ~
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ datalad install -s /neurodesktop-storage/SomeProject
</span></span><span style=display:flex><span>install(ok): /home/user/SomeProject (dataset)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ cd SomeProject</span></span></code></pre></div></div><p>Because a DataLad dataset is a Git repository, people who download your dataset
can see exactly how <code>outputs/hello.txt</code> was created using Git&rsquo;s logs.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ git log outputs/hello.txt
</span></span><span style=display:flex><span>commit 52cff839596ff6e33aadf925d15ab26a607317de (HEAD -&gt; master, origin/master, origin/HEAD)
</span></span><span style=display:flex><span>Author: Neurodesk User &lt;user@neurodesk.github.io&gt;
</span></span><span style=display:flex><span>Date:   Thu Dec 9 08:31:15 2021 +0000
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    [DATALAD RUNCMD] run hello
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    === Do not change lines below ===
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>     &#34;chain&#34;: [],
</span></span><span style=display:flex><span>     &#34;cmd&#34;: &#34;julia code/hello.jl &gt; outputs/hello.txt&#34;,
</span></span><span style=display:flex><span>     &#34;dsid&#34;: &#34;1e82813d-856f-4118-b54d-c3823e025709&#34;,
</span></span><span style=display:flex><span>     &#34;exit&#34;: 0,
</span></span><span style=display:flex><span>     &#34;extra_inputs&#34;: [],
</span></span><span style=display:flex><span>     &#34;inputs&#34;: [],
</span></span><span style=display:flex><span>     &#34;outputs&#34;: [
</span></span><span style=display:flex><span>      &#34;outputs/hello.txt&#34;
</span></span><span style=display:flex><span>     ],
</span></span><span style=display:flex><span>     &#34;pwd&#34;: &#34;.&#34;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    ^^^ Do not change lines above ^^^</span></span></code></pre></div></div><p>Then, using that information, they can re-run the command that created the file
using <code>datalad rerun</code>!</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$ datalad rerun 52cf
</span></span><span style=display:flex><span>[INFO   ] run commit 52cff83; (run hello)
</span></span><span style=display:flex><span>run.remove(ok): outputs/hello.txt (file) [Removed file]
</span></span><span style=display:flex><span>[INFO   ] == Command start (output follows) =====
</span></span><span style=display:flex><span>[INFO   ] == Command exit (modification check follows) =====
</span></span><span style=display:flex><span>add(ok): outputs/hello.txt (file)
</span></span><span style=display:flex><span>action summary:
</span></span><span style=display:flex><span>  add (ok: 1)
</span></span><span style=display:flex><span>  run.remove (ok: 1)
</span></span><span style=display:flex><span>  save (notneeded: 1)</span></span></code></pre></div></div><div class="alert alert-primary" role=alert><h4 class=alert-heading>git</h4>In Git, each commit (save state) is assigned a long,
unique machine-generated ID. <code>52cf</code> refers to the commit with ID that starts
with those characters. Usually 4 is the minimum needed to uniquely identify a
commit. Of course, this ID is probably different for you, so change this
argument to match your commit.</div><h2 id=see-also>See Also</h2><ul><li>To learn more basics and advanced applications of DataLad, check out the
<a href=http://handbook.datalad.org/en/latest/ target=_blank rel=noopener>DataLad Handbook</a>.</li><li>DataLad is built on top of the popular version control tool <strong>Git</strong>. There
are many great resources on Git online, like this <a href=https://git-scm.com/book/en/v2 target=_blank rel=noopener>free book</a>.</li><li>DataLad is only available on the terminal. For a detailed introduction on the
Bash terminal, check the <a href=https://mywiki.wooledge.org/BashGuide target=_blank rel=noopener>BashGuide</a>.</li><li>For even more reproducibility, you can include <em>containers</em> with your dataset
to run analyses in. DataLad has an extension to support script execution in
containers. See <a href=http://handbook.datalad.org/en/latest/basics/101-133-containersrun.html target=_blank rel=noopener>here</a>.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-44b4ec1d6c2eb6a75f361c94caac8f65>2.8 - Spectroscopy</h1><div class=lead>Tutorials about performing MR spectroscopy analyses</div></div><div class=td-content><h1 id=pg-16bdca40061ec1ad8bd42400513f337c>2.8.1 - Spectroscopy with lcmodel</h1><div class=lead>Using lcmodel, you can analyze MR spectroscopy data.</div><blockquote><p><em>This tutorial was created by Steffen Bollmann.</em></p><p>Github: <a href=https://github.com/stebo85 target=_blank rel=noopener>@stebo85</a>
Web: <a href=https://mri.sbollmann.net/ target=_blank rel=noopener>mri.sbollmann.net</a>
Twitter: <a href=https://twitter.com/sbollmann_MRI target=_blank rel=noopener>@sbollmann_MRI</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><p>Open lcmodel from the menu: Applications -> Spectroscopy -> lcmodel -> lcmodel 6.3</p><p>run</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>setup_lcmodel.sh</span></span></code></pre></div></div><p>then run</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>lcmgui</span></span></code></pre></div></div><p>We packed example data into the container (<a href=https://zenodo.org/record/3904443/ target=_blank rel=noopener>https://zenodo.org/record/3904443/</a>) and we will use this to show a basic analysis.</p><p>The example data comes in the Varian fid format, so click on Varian:</p><img width=522 alt=image src=https://user-images.githubusercontent.com/4021595/155111509-967055c2-7ee1-4bf5-b645-6a0b1eee3328.png><p>and then select the fid data in: /opt/datasets/Spectra_hippocampus(rat)_TE02/s_20131015_03_BDL106_scan0/isise_01.fid</p><img width=751 alt=image src=https://user-images.githubusercontent.com/4021595/155111715-305678e9-0c60-4154-bdf3-3aa5ccfd7da1.png><p>Then Change BASIS and select the appropriate basis set in /opt/datasets/Spectra_hippocampus(rat)_TE02/Control_files_Basis_set</p><img width=753 alt=image src=https://user-images.githubusercontent.com/4021595/155111920-9df07a57-beb1-4507-ab7e-2c260a52d91d.png><p>Then hit Run LCModel:</p><img width=812 alt=image src=https://user-images.githubusercontent.com/4021595/155112027-11350513-7616-4158-aca7-d5c0b07397d0.png><p>and confirm:</p><img width=199 alt=image src=https://user-images.githubusercontent.com/4021595/155112122-1b93ff25-7469-4997-8aa6-e96a6784defa.png><p>then wait a couple of minutes until the analyzed spectra appear - by closing the window you can go through the results:</p><img width=893 alt=image src=https://user-images.githubusercontent.com/4021595/155112432-c91bbdef-4701-4fee-a37a-b3bf8f847843.png><p>the results are also saved in ~/.lcmodel/saved/</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9c021f0163fdf28321444103760ba8ce>2.8.2 - Spectroscopy pipeline</h1><div class=lead>Using mrsiproc, you can reconstruct and analyze MR spectroscopy data.</div><blockquote><p><em>This tutorial was created by Korbinian Eckstein.</em></p><p>Github: <a href=https://github.com/korbinian90/ target=_blank rel=noopener>@korbinian90</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><div class="alert alert-primary" role=alert><h4 class=alert-heading>Processing MRSI</h4><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>ml mrsiproc/0.1.0</span></span></code></pre></div></div><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>bash Part1_ProcessMRSI.sh [ARGUMENTS]</span></span></code></pre></div></div><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>bash Part2_EvaluateMRSI.sh [ARGUMENTS]</span></span></code></pre></div></div></div><h2 id=starting-neurodesk>Starting Neurodesk</h2><p>After starting Neurodesk, a JupyterLab instance should open. You can either work from here or open a desktop environment by clicking <code>Neurodesktop</code> under <code>Notebooks</code>. This tutorial uses the desktop.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/spectroscopy/mrsiproc/jupyterlab.png alt=JupyterLab title=JupyterLab></p><h2 id=running-mrsi-reconstruction>Running MRSI reconstruction</h2><p>Open vscode and create and open a new folder under <code>neurodesktop-storage</code></p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/spectroscopy/mrsiproc/open_folder.png alt="Open Folder" title="Open Folder"></p><div class="alert alert-primary" role=alert><h4 class=alert-heading>Info</h4><p>The processing can either start from reconstructed DICOM files or exported dat files.
A reconstruction of a dat files might look like this:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Part1_ProcessMRSI.sh \
</span></span><span style=display:flex><span>-c /neurodesktop-storage/data/meas_test.dat \
</span></span><span style=display:flex><span>-t /neurodesktop-storage/data/T1/ \
</span></span><span style=display:flex><span>-a /neurodesktop-storage/data/INV1/ \
</span></span><span style=display:flex><span>-b fid_1.300000ms.basis \
</span></span><span style=display:flex><span>-o /neurodesktop-storage/mrsi_proc/ProcessResults/test_files \
</span></span><span style=display:flex><span>-j LCModel_Control_Template.m \
</span></span><span style=display:flex><span>-m &#34;dreid&#34;</span></span></code></pre></div></div><p>The <code>fid_1.300000ms.basis</code> and <code>LCModel_Control_Template.m</code> files are included</p></div><p>Here, we create a new bash file with the default settings and execute it. Copy the contents of this template file to <code>run_mrsi_part1.sh</code> and replace the <code>-c</code>, <code>-t</code> and <code>-a</code> arguments with your own data and set the output path with <code>-o</code>.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#57606a>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#57606a></span><span style=color:#57606a># There are two script to process the mrsi data</span>
</span></span><span style=display:flex><span><span style=color:#57606a># First run this script, then run the part 2 script</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ml mrsiproc/0.1.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## The required files are:</span>
</span></span><span style=display:flex><span><span style=color:#57606a># - DAT file / DICOM files</span>
</span></span><span style=display:flex><span><span style=color:#57606a># - T1 (DICOM or .mnc)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## Create own mask (not fully supported yet)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># hd-bet -i /neurodesktop-storage/mrsi_proc/test_files/MP2RAGE/t1.nii.gz -o /neurodesktop-storage/mrsi_proc/test_files/mask.nii.gz -device cpu -mode fast -tta 0</span>
</span></span><span style=display:flex><span><span style=color:#57606a># nii2mnc /neurodesktop-storage/mrsi_proc/test_files/mask.nii.gz /neurodesktop-storage/mrsi_proc/test_files/mask.mnc</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Part1_ProcessMRSI.sh <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-c /neurodesktop-storage/data/meas_test.dat <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-t /neurodesktop-storage/data/T1/ <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-a /neurodesktop-storage/data/INV1/ <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-b fid_1.300000ms.basis <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-o /neurodesktop-storage/mrsi_proc/ProcessResults/test_files <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-j LCModel_Control_Template.m <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-m <span style=color:#0a3069>&#34;dreid&#34;</span> <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-L <span style=color:#0a3069>&#34;L2,0.2&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## HINT</span>
</span></span><span style=display:flex><span><span style=color:#57606a># To change the number of threads used by LCModel, change the number in the LCModel_Control_Template.m file (default 8)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## WARNING -s</span>
</span></span><span style=display:flex><span><span style=color:#57606a># The Julia based recontstruction is still experimental! The algorithm is different, and the results are not expected to be identical. It should be identical to the DICOM output from the ICE version.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## WARNING -m</span>
</span></span><span style=display:flex><span><span style=color:#57606a># If a mask file is given, it must be in *.mnc format</span>
</span></span><span style=display:flex><span><span style=color:#57606a># The word &#34;bet&#34; may not be part of the filename of the mask given to the -m flag</span>
</span></span><span style=display:flex><span><span style=color:#57606a># For a 3D mask, it is suggested to use -m &#34;dreid&#34; instead of -m &#34;bet&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## WARNING -t</span>
</span></span><span style=display:flex><span><span style=color:#57606a># The DICOM folder for giving the T1-weighted image must not contain any other files than *.IMA</span>
</span></span><span style=display:flex><span><span style=color:#57606a># The t1-weighted file can be given as *.mnc file as well</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## The OPTIONS are</span>
</span></span><span style=display:flex><span><span style=color:#57606a># Usage: %s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># mandatory:</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -c	[csi file]			Format: DAT, DICOM, or .mat. If a .mat file is passed over, it is expected that everything is already performed like coil combination etc.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 						You can pass over several files of the same type by \&#39;-c \&#34;[csi_path1] [csi_path2] ...\&#34;\&#39;. These files get individually processed and averaged</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 						at the end.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -b	[basis files]		Format: .BASIS. Used for LCM fitting (for FID)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -B	[basis files]		Format: .BASIS. Used for LCM fitting (spin echo: for fidesi =  fid + echo)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -o	[output directory]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># optional: </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -i	[image NORMAL]		Format: DAT or DICOM. The FoV must match that of the CSI file. Used for our coil combination and for creating mask (if no T1 is inputted)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -f	[image FLIP]		Format: DAT or DICOM. Imaging file FLIP (FOV rotated about -180 deg). Used for correcting gradient delays.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -v	[VC image]	      	Format: DAT or DICOM. Image of volume or body coil file. Used for sensmap method or for creating mask.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -t	[T1 images] 		Format: DICOM. Folder of 3d T1-weighted acquisition containing DICOM files. Used for creating mask and for visual purposes. If minc file is given instead of folder, it is treated as the magnitude file.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -a	[T1 AntiNoise images]	Format: DICOM. Folder of 3d T1-weighted acquisition containing DICOM files. Used for pre-masking the T1w image to get rid of the noise in air-areas.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -w	[Water Reference]	Format: DAT or DICOM. LCModel &#39;Do Water Scaling&#39; or separate water quantification (Water maps are created). The same scan as -c [csi file], but without water suppression.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -m	[mask]			Defines how to create the mask. Options: -m \&#34;bet\&#34;, \&#34;thresh\&#34;, \&#34;voi\&#34;, \&#34;[Path_to_usermade_mask]\&#34;. If not set --&gt; no mask used.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -h 	[100]               	Hamming filter CSI data.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -r 	[InPlaneCaipPattern_And_VD_Radius]	The InPlaneCaipPattern and the VD_Radius as used in ParallelImagingSimReco.m. Example: \&#34;InPlaneCaipPattern = [0 0 0; 0 0 0; 0 0 1]; VD_Radius = 2;\&#34;. </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -R 	[SliceAliasingPattern]</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -g 	[noisedecorr_path]	If this option is used the csi data gets noise decorrelated using noise from passed-over noise file, or if -g \&#34; is given, by noise from the end of the FIDs at the border of the FoV or from the PRESCAN, if available. </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -F    [Nothing]               If this option is set, the spectra are corrected for the first order phase caused by an acquisition delay of the FID-sequences. You must provide a basis set with an appropriate acquisition delay. DONT USE WITH SPIN ECHO SEQUENCES.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -u	[Nothing]               If a phantom was measured. Different settings used for fitting (e.g. some metabolites are omitted)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -I	[\&#34;nextpow2\&#34; Or Vector]If nextpow2: Perform zerofilling to the next power of 2 in ROW and COL dimensions (e.g. from 42x42 to 64x64). If vector (e.g. [16 16 1]): Spatially Interpolate to this size.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -A	[\&#34;\&#34; Or Path]          Perform frequency alignment. If a mnc file is given, use these as B0-map, otherwise shift according to water peak of center voxel.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -l	[Nothing]               If this option is set, LCModel is not started, everything else is done normally. Useful for only computing the SNR.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -j	[LCM_ControlFile]       ControlFile telling LCModel how to process the data. for FID</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -J	[LCM_ControlFile]       ControlFile telling LCModel how to process the data. for ECHO</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -X	[XPACE MOTION LOG]       XPACE MOTION LOG</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 							otherwise standard values are assumed. A template file is provided in this package.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -e	[LineBroadeningInHz]    Apply an exponential filter to the spectra [Hz].</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -s	[threads] [mmap] 		Use the Julia reconstruction version (less RAM usage, different reconstruction algorithm). [threads=auto] can be auto or a number. [mmap=false] can be \&#34;true\&#34;, \&#34;false\&#34; or a path.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -d    [Nothing]				Use the deprecated, old dat file format (before sequence merging, 06/2023)</span></span></span></code></pre></div></div><p>Then run the script with</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>bash run_mrsi_part1.sh</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/spectroscopy/mrsiproc/run_mrsi.png alt="Run MRSI" title="Run MRSI"></p><p>This can take several hours for reconstruction and LCModel processing.</p><h2 id=part-2>Part 2</h2><p>Continue with the same process for part 2<br>Template file for part 2</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#57606a>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#57606a></span>
</span></span><span style=display:flex><span>ml mrsiproc/0.1.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Part2_EvaluateMRSI.sh <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-o neurodesktop-storage/mrsi_proc/ProcessResults/test_files <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-S <span style=color:#0a3069>&#34;Glu,Gln,Raw-abs-csi&#34;</span> <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-N Nifti <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-R <span style=color:#0a3069>\
</span></span></span><span style=display:flex><span><span style=color:#0a3069></span>-b
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a>## The OPTIONS are</span>
</span></span><span style=display:flex><span><span style=color:#57606a># Usage: %s</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># mandatory:</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -o	[output directory]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># optional: </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -d	[print_indiv..._flag]   If this option is set, the SNR gets computed by our own program. If the</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                print_individual_spectra_flag=1 (by using option -d 1) all spectra for </span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                computing the SNR are printed.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -b    [segmentation_matrix_size]</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                If segmentation to GM, WM and CSF should be performed.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#57606a># -s	[CRLB_treshold_value]	user can set the treshold value for CRLB in the metabolic maps</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -n	[SNR_treshold_value]    If this option is set (user set the value of SNR threshold after the flag),</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                SNR binary mask is computed either for LC model SNR or (if the -d flag is set) for</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                custom SNR computation method and LCmodel            </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -f	[FWHM_treshold_value]   If this option is set (user set the value of FWHM threshold after the flag),</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                FWHM binary mask is computed from LCmodel results</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -a    [Control file]          Compute SNR with home-brewed script.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -l    [local_folder]          Perform some of the file-heavy tasks in \$local_folder/tmpx (x=1,2,3,...) instead of on \$out_dir</span>
</span></span><span style=display:flex><span><span style=color:#57606a>#                               directly. This is faster, and if \$out_dir is mounted via nfs4, writing directly to \$out_dir</span>
</span></span><span style=display:flex><span><span style=color:#57606a>#                               can lead to timeouts and terrible zombie processes. </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -k	[spectra_stack_range]	If this option is set, the .Coord files from LCmodel are used to create stacks of spectra</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                to visualize the fit in corresponding voxels (results stored in form of .eps)</span>
</span></span><span style=display:flex><span><span style=color:#57606a>#       				        user can set the starting point of range for stack of spectra for display purposes (in ppm)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                user can set the ending point of range for stack of spectra for display purposes (in ppm)</span>
</span></span><span style=display:flex><span><span style=color:#57606a># 				                Options: \&#34;[&#39;fullrange&#39;]\&#34;, \&#34;[ppm_start; ppm_end]\&#34;</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -r	[non_lin_reg_type]	    If this option is set, the non-linear registration is computed using minctools, Options: -r \&#34;MNI305\&#34;, \&#34;MNI152\&#34;</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -w	[compute_reg_only_flag] If this option is set, only the non-linear registration is computed. </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -q	[compute_seg_only_flag] If this option is set, only the segmentation is computed. </span>
</span></span><span style=display:flex><span><span style=color:#57606a># -N    [\&#34;Nifti\&#34; or \&#34;Both\&#34;] Only create nifti-files. If \&#34;Both\&#34; option is used, create minc and nifti. If -N option is not used, creat only mnc files.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -S    [SpectralMap_flag] 		Create a nifti-file with a map of the LCModel-spectra and -fits to view with freeview as timeseries.\nNeeds freesurfer-linux-centos7_x86_64-dev-20181113-8abd50c, and MATLAB version &gt; R2017b. Can only be used with -N option.</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -u    [UpsampledMaps_flag]	Create upsampled maps by zero-filling (in future more sophisticated methods might be implemented).</span>
</span></span><span style=display:flex><span><span style=color:#57606a># -R    [RatioMaps_flag]		Create Ratio maps.</span></span></span></code></pre></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-7cb11988e9ff6c4a545699afff23592f>2.9 - Structural Imaging</h1><div class=lead>Tutorials about processing structural MRI data</div></div><div class=td-content><h1 id=pg-ba2f27cb888361d8d7116fb59180cdad>2.9.1 - FreeSurfer</h1><div class=lead>Example workflow for FreeSurfer</div><blockquote><p><em>This tutorial was created by Steffen Bollmann.</em></p><p>Github: <a href=https://github.com/stebo85 target=_blank rel=noopener>@stebo85</a>
Web: <a href=https://mri.sbollmann.net/ target=_blank rel=noopener>mri.sbollmann.net</a>
Twitter: <a href=https://twitter.com/sbollmann_MRI target=_blank rel=noopener>@sbollmann_MRI</a></p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=freesurfer-example-using-module-load-eg-on-an-hpc>FreeSurfer Example using module load (e.g. on an HPC)</h2><p>Download data:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>osf -p bt4ez fetch osfstorage/TOMCAT_DIB/sub-01/ses-01_7T/anat/sub-01_ses-01_7T_T1w_defaced.nii.gz sub-01_ses-01_7T_T1w_defaced.nii.gz</span></span></code></pre></div></div><p>Setup FreeSurfer:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span>ml freesurfer<span style=color:#0550ae>/</span><span style=color:#0550ae>7.3</span><span style=color:#0550ae>.</span><span style=color:#0550ae>2</span>
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> SUBJECTS_DIR<span style=color:#0550ae>=$</span>PWD<span style=color:#0550ae>/</span>freesurfer<span style=color:#0550ae>-</span>output
</span></span><span style=display:flex><span>mkdir <span style=color:#0550ae>$</span>SUBJECTS_DIR
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> SINGULARITYENV_SUBJECTS_DIR<span style=color:#0550ae>=$</span>SUBJECTS_DIR
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> APPTAINERENV_SUBJECTS_DIR<span style=color:#0550ae>=$</span>SUBJECTS_DIR</span></span></code></pre></div></div><p>Run Recon all pipeline:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>recon-all -subject test-subject -i sub-01_ses-01_7T_T1w_defaced.nii.gz -all</span></span></code></pre></div></div><p>When using Freesurfer >8.0.0:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#cf222e>export</span> FS_ALLOW_DEEP<span style=color:#0550ae>=</span><span style=color:#0550ae>1</span>
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> APPTAINERENV_FS_ALLOW_DEEP<span style=color:#0550ae>=$</span>FS_ALLOW_DEEP
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> SINGULARITYENV_FS_ALLOW_DEEP<span style=color:#0550ae>=$</span>FS_ALLOW_DEEP</span></span></code></pre></div></div><p>When running on a GPU, make sure to check if this is set:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#cf222e>export</span> neurodesk_singularity_opts<span style=color:#0550ae>=</span><span style=color:#0a3069>&#39;--nv&#39;</span></span></span></code></pre></div></div><h2 id=alternative-instructions-for-using-freesurfer-via-the-neurodesk-application-menu>Alternative instructions for using Freesurfer via the Neurodesk application menu</h2><h3 id=download-demo-data>Download demo data</h3><p>Open a terminal and run:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>pip install osfclient
</span></span><span style=display:flex><span>osf -p bt4ez fetch TOMCAT_DIB/sub-01/ses-01_7T/anat/sub-01_ses-01_7T_T1w_defaced.nii.gz /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz</span></span></code></pre></div></div><h3 id=freesurfer-license-file>FreeSurfer License file:</h3><p>Before using Freesurfer you need to request a license here (<a href=https://surfer.nmr.mgh.harvard.edu/registration.html target=_blank rel=noopener>https://surfer.nmr.mgh.harvard.edu/registration.html</a>) and store it in your homedirectory as ~/.license</p><h3 id=freesurfer-example>FreeSurfer Example</h3><p>Open FreeSurfer (Neurodesk -> Image Segmentation -> Freesurfer -> Freesurfer 7.1.1)</p><p>Setup FreeSurfer license (for example - replace with your license):</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span>echo <span style=color:#0a3069>&#34;Steffen.Bollmann@cai.uq.edu.au</span>
</span></span><span style=display:flex><span><span style=color:#0550ae>&gt;</span> <span style=color:#0550ae>21029</span>
</span></span><span style=display:flex><span><span style=color:#0550ae>&gt;</span>  <span style=color:#0550ae>*</span>Cqyn12sqTCxo
</span></span><span style=display:flex><span><span style=color:#0550ae>&gt;</span>  FSxgcvGkNR59Y<span style=color:#0a3069>&#34; &gt;&gt; ~/.license</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> FS_LICENSE<span style=color:#0550ae>=~/.</span>license </span></span></code></pre></div></div><p>Setup FreeSurfer:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span>mkdir <span style=color:#0550ae>/</span>neurodesktop<span style=color:#0550ae>-</span>storage<span style=color:#0550ae>/</span>freesurfer<span style=color:#0550ae>-</span>output
</span></span><span style=display:flex><span>source <span style=color:#0550ae>/</span>opt<span style=color:#0550ae>/</span>freesurfer<span style=color:#0550ae>-</span><span style=color:#0550ae>7.1</span><span style=color:#0550ae>.</span><span style=color:#0550ae>1</span><span style=color:#0550ae>/</span>SetUpFreeSurfer<span style=color:#0550ae>.</span>sh
</span></span><span style=display:flex><span><span style=color:#cf222e>export</span> SUBJECTS_DIR<span style=color:#0550ae>=/</span>neurodesktop<span style=color:#0550ae>-</span>storage<span style=color:#0550ae>/</span>freesurfer<span style=color:#0550ae>-</span>output</span></span></code></pre></div></div><p>Run Recon all pipeline:</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>recon-all -subject test-subject -i /neurodesktop-storage/sub-01_ses-01_7T_T1w_defaced.nii.gz -all</span></span></code></pre></div></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f5bb7d50ecc788ed52db3c1c8985c081>2.9.2 - Structural connectivity dMRI</h1><div class=lead>Example workflow for constructing strutural connectivity (Human connectome project: Single subject)</div><blockquote><p><em>This tutorial was created by Joan Amos.</em></p><p>Email: <a href=mailto:joan@std.uestc.edu.cn>joan@std.uestc.edu.cn</a>
Github: @Joanone</p></blockquote><div class="alert alert-info" role=alert><h4 class=alert-heading>Getting Setup with Neurodesk</h4><i>For more information on getting set up with a Neurodesk environment, see <a href=https://neurodesk.org/tutorials-examples>here</a></i></div><h2 id=references>References:</h2><p>The steps used for this tutorial were from:</p><ul><li><a href=https://github.com/civier/HCP-dMRI-connectome target=_blank rel=noopener>https://github.com/civier/HCP-dMRI-connectome</a></li><li><a href=https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_00_Diffusion_Overview.html target=_blank rel=noopener>https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_00_Diffusion_Overview.html</a></li><li><a href=https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/structural_connectome.html target=_blank rel=noopener>https://mrtrix.readthedocs.io/en/latest/quantitative_structural_connectivity/structural_connectome.html</a></li></ul><h2 id=data-description>Data Description</h2><h3 id=reference>Reference:</h3><p>The single subject data (T1w structural and diffusion) used in this tutorial has been minimally preprocessed and was downloaded from the open available source:</p><p>db.humanconnectome.org</p><h3 id=download-demo-data>Download demo data:</h3><p>Demo data can also be downloaded using these links below.</p><ul><li><a href="https://drive.google.com/file/d/1bj-Tz2xLGn0L05CveOYnzTgkewc_IU5F/view?usp=drive_link" target=_blank rel=noopener>https://drive.google.com/file/d/1bj-Tz2xLGn0L05CveOYnzTgkewc_IU5F/view?usp=drive_link</a> [T1w structural data]</li><li><a href="https://drive.google.com/file/d/193ZaUmXbT59IoXoAJ-Y1pf_wgdSHdKpR/view?usp=drive_link" target=_blank rel=noopener>https://drive.google.com/file/d/193ZaUmXbT59IoXoAJ-Y1pf_wgdSHdKpR/view?usp=drive_link</a> [Diffusion data]</li></ul><h2 id=assumptions>Assumptions:</h2><ul><li>You have neurodesk already running from your chrome browser.</li><li>You have sufficient disk space to successfully implement the structural connectivity.</li><li>The structural and diffusion sample data have been unzipped in the mounted storage directory.</li></ul><h3 id=sample-subject-100307-directory-tree-structure-should-include-these-input-files>Sample Subject (100307) directory tree structure should include these input files:</h3><ul><li>aparc+aseg.nii.gz</li><li>T1w_acpc_dc_restore_brain.nii.gz</li><li>bvals</li><li>bvecs</li><li>data.nii.gz</li></ul><h3 id=navigate-to-the-mounted-storage--more-data--create-a-new-folder-of-your-choice--copy-the-required-input-files-into-a-folder--100307>Navigate to the mounted storage → more data → Create a new folder of your choice → copy the required input files into a folder → 100307</h3><p>N/B: The subfolder used in this tutorial was tagged &ldquo;Test&rdquo;</p><p>Open a terminal in neurodesk and confirm your input files:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/01_start.png alt=structuralconnectivity></p><h3 id=activate-mrtrix3-fsl-and-afni-software-versions-of-your-choice-in-the-neurodesk-terminal>Activate mrtrix3, fsl and afni software versions of your choice in the neurodesk terminal</h3><p>N/B: mrtrix3 (3.0.3), afni (21.2.00), fsl(6.0.5.1) versions were used in this tutorial. For reproducibility, the same versions can be maintained.</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/02_activate_softwares.png alt=structuralconnectivity></p><h2 id=step-1-further-pre-processing>Step 1: Further pre-processing</h2><p>Extract data.nii.gz to enable memory-mapping. The extracted files are about 4.5GB:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/03_preproc.png alt=structuralconnectivity></p><p>Perform mrconvert:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/04_preproc.png alt=structuralconnectivity></p><p>Extract the response function. Uses stride 0,0,0,1:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/05_preproc.png alt=structuralconnectivity></p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/06_preproc.png alt=structuralconnectivity></p><p>Generate mask:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/07_preproc.png alt=structuralconnectivity></p><p>Generate Fibre Orientation Distributions (FODs):</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/08_preproc.png alt=structuralconnectivity></p><p>Perform normalization:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/09_preproc.png alt=structuralconnectivity></p><p>Generate a 5 tissue image:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/10_preproc.png alt=structuralconnectivity></p><p>Convert the B0 and 5TT image to a compressed format:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/11_preproc.png alt=structuralconnectivity></p><p>Use &ldquo;fslroi&rdquo; to extract the first volume of the segmented dataset which corresponds to the Grey Matter Segmentation:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/12_preproc.png alt=structuralconnectivity></p><p>Use &ldquo;flirt&rdquo; command to perform coregisteration:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/13_preproc.png alt=structuralconnectivity></p><p>Convert the transformation matrix to a format readable by MRtrix3:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/14_preproc.png alt=structuralconnectivity></p><p>Coregister the anatomical image to the diffusion image:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/15_preproc.png alt=structuralconnectivity></p><p>Create the seed boundary which separates the grey from the white matter. The command &ldquo;5tt2gmwmi&rdquo; denotes (5 tissue type(segmentation) to grey matter/white matter interface):</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/16_preproc.png alt=structuralconnectivity></p><h2 id=step-2-tractogram-construction>Step 2: Tractogram construction</h2><p>The probabilistic tractography which is the default in MRtrix is used in this tutorial. The default method is the iFOD2 algorithm.
The number of streamlines used is 10 million, this was chosen to save computational time:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/17_tractogram.png alt=structuralconnectivity></p><p>Proceed to Step 3 when the process above is completed (100%).</p><h2 id=step-3-sift2-construction>Step 3: SIFT2 construction</h2><p>The generated streamlines can be refined with tcksift2 to counterbalance the overfitting. This creates a text file containing weights for each voxel in the brain:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/18_sift2.png alt=structuralconnectivity></p><h2 id=step-4-connectome-construction>Step 4: Connectome construction</h2><p>In constructing the connectome, the desikan-killany atlas which includes the cortical and sub-cortical regions (84 regions) was used.</p><p>Copy the &ldquo;FreeSurferColorLUT.txt&rdquo; file from the ml freesurfer 7.2.0 singularity container to the subject&rsquo;s folder:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/19_connectome.png alt=structuralconnectivity>
<img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/20_connectome.png alt=structuralconnectivity></p><p>Copy the &ldquo;fs_default.txt&rdquo; file from the ml mrtrix3 3.0.3 singularity container to the subject&rsquo;s folder:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/21_connectome.png alt=structuralconnectivity></p><p>The command labelconvert uses the parcellation and segmentation output of FreeSurfer to create a new parcellated file in .mif format:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/22_connectome.png alt=structuralconnectivity></p><p>Perform nodes co-registeration:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/23_connectome.png alt=structuralconnectivity></p><p>Create a whole-brain connectome which denotes the streamlines between each parcellation pair in the atlas. The &ldquo;symmetric&rdquo; option makes the lower and upper diagonal the same, the &ldquo;scale_invnodevol&rdquo; option scales the connectome by the inverse of the size of the node:</p><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/24_connectome.png alt=structuralconnectivity></p><h2 id=viewing-the-connectome>Viewing the connectome</h2><p>The generated nodes.csv file can be viewed outside neurodesk as a matrix in Matlab.</p><div class=highlight><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>connectome=importdata(&#39;nodes.csv&#39;);
</span></span><span style=display:flex><span>imagesc(connectome,[0 1])</span></span></code></pre></div></div><p><img src=https://neurodesk.org/static/tutorials-examples/tutorials/structural_imaging/structuralconnectivity/25_connectome.png alt=structuralconnectivity></p><p>Congratulations on constructing a single subject&rsquo;s structural connectome with neurodesk! Running multiple subjects would require scripting. Kindly consult the references above.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f30f6c05cb5c5bd067c06745b469d13d>3 - Contribute Tutorials and Example Notebooks</h1><div class=lead>A brief guide for contributing new tutorials and example notebooks.</div><p>Neurodesk welcomes community-contributed content. We aim to collect a wide variety of tutorials and examples representing the spectrum of tools available under the Neurodesk architecture and the diversity in how researchers might apply them. Sharing your expertise helps others learn and supports reproducible research.</p><ul><li>A <strong>tutorial</strong>: Markdown-based, concise step-by-step documentation integrated into the website, for using specific neuroimaging software on neurodesk with screenshots for visual aid</li><li>An <strong>example notebook</strong>: Jupyter notebooks that illustrate tool usage or analysis pipelines are stored in a separate repository. These notebooks can be interactive and are ideal for showcasing scripts, visualizations, or code-driven workflows.</li></ul><hr><h2 id=how-to-contribute>How to Contribute</h2><p>To contribute a new tutorial or example notebook:</p><ol><li><p><strong>Start from the template</strong><br>Use the <a href=https://github.com/neurodesk/neurodesk.github.io/blob/main/.github/content-templates/tutorial-template.md target=_blank rel=noopener>tutorial template</a> or the <a href=https://github.com/Neurodesk/example-notebooks/blob/main/template.ipynb target=_blank rel=noopener>example notebook template</a> as a starting point. They include recommended formatting and structure.</p></li><li><p><strong>Follow the documentation style</strong><br>Write clearly and concisely. Include any necessary prerequisites, commands, and expected outputs.</p><ul><li>Tutorials should use Markdown with well-formatted headings, lists, and code blocks</li><li>Notebooks should be well-commented and executable from start to finish</li></ul></li><li><p><strong>Save your content</strong></p><ul><li><p>For <strong>tutorials</strong>: add your Markdown file to the
<a href=https://github.com/NeuroDesk/neurodesk.github.io/tree/main/content/en/tutorials-examples/tutorials target=_blank rel=noopener>Github neurodesk.github.io: tutorials folder</a></p></li><li><p>For <strong>example notebooks</strong>: add your <code>.ipynb</code> file to the
<a href=https://github.com/Neurodesk/example-notebooks/tree/main/books target=_blank rel=noopener>Github example-notebooks: books folder</a></p></li></ul></li><li><p><strong>Submit your contribution</strong></p><ul><li>Open a pull request to the appropriate repository</li><li>Include a brief summary of what your tutorial or notebook covers</li><li>Check that any links, figures, or code blocks are working and properly rendered</li></ul></li></ol><hr><h2 id=tips-for-good-tutorials>Tips for Good Tutorials</h2><ul><li>Focus on a specific tool or workflow</li><li>Include sample commands and outputs</li><li>Keep it as reproducible by using open dataset</li><li>Link to any relevant containers, documentation, or datasets</li></ul><hr><h2 id=attribution>Attribution</h2><p>We credit all tutorial contributors on the <a href=https://neurodesk.org/developers/contributors/>Contributors page</a>.<br>If you would like to be listed, please include your name and a short description in your pull request, following <a href=https://github.com/NeuroDesk/neurodesk.github.io/blob/main/.github/content-templates/contributor-format.md target=_blank rel=noopener>this format</a>.</p><p>In addition, each example notebook receives a DOI for formal attribution through Zenodo. This ensures that your contribution is citable and can be referenced in academic publications.</p><hr><h2 id=need-help>Need Help?</h2><p>If you have questions or would like feedback before submitting, feel free to open a <a href=https://github.com/NeuroDesk/neurodesk.github.io/discussions target=_blank rel=noopener>discussion</a>.</p><p>Thank you for helping build a more accessible and collaborative neuroimaging community.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-2bf6c1d7ca51b83e9ff5c9b3cf6a5f16>3.1 - Contribute Example Notebooks</h1><div class=lead>A brief guide for contributing new example notebooks.</div><p>We welcome example notebooks that demonstrate how to use tools within Neurodesk. These notebooks serve as valuable learning resources and promote reproducible workflows across the neuroimaging community.</p><p>Example notebooks are hosted in the <a href=https://github.com/Neurodesk/example-notebooks target=_blank rel=noopener><code>neurodesk/example-notebooks</code></a> repository and are intended to be lightweight, self-contained, and easy to follow.</p><hr><h2 id=getting-started>Getting Started</h2><p>To contribute a new notebook, follow the steps below:</p><h3 id=1-start-from-the-template>1. Start from the template</h3><p>Use the official <a href=https://github.com/Neurodesk/example-notebooks/blob/main/template.ipynb target=_blank rel=noopener>example notebook template</a> as a starting point. It includes guidance on formatting, structure, metadata, and citation instructions.</p><p>Each notebook should contain:</p><ul><li>A clear title and short description - aim for a short title that will fit in the left menu</li><li>An overview of the tool or workflow demonstrated</li><li>The container/tool version used</li><li>Code cells with explanatory comments</li><li>Example data (or guidance on how to access it)</li></ul><div class="alert alert-primary" role=alert><h4 class=alert-heading>Python packages</h4>please consult the python packages included in the base image <a href=https://github.com/neurodesk/neurodesktop/blob/main/Dockerfile target=_blank rel=noopener>see list here</a>. If you are using python packages different than these, be sure to <code>pip install</code> them in the workflow</div><h3 id=2-follow-best-practices>2. Follow best practices</h3><ul><li>Keep notebooks self-contained and executable top to bottom. Before being published, a Github Action will confirm the Notebook is working.</li><li>Avoid hardcoded file paths where possible</li><li>Use publicly accessible datasets</li><li>Include inline comments and Markdown cells for explanation</li></ul><p>For more detail, consult the <a href=https://github.com/Neurodesk/example-notebooks#readme target=_blank rel=noopener>README in the example-notebooks repository</a>.</p><hr><h2 id=saving-and-submitting>Saving and Submitting</h2><ol><li><p>Add your completed notebook to the appropriate folder under:</p><p><a href=https://github.com/Neurodesk/example-notebooks/tree/main/books target=_blank rel=noopener><code>/books/</code></a></p></li><li><p>Open a pull request in the <a href=https://github.com/Neurodesk/example-notebooks target=_blank rel=noopener>example-notebooks repository</a></p></li><li><p>In your pull request, include:</p><ul><li>A short description of your notebook</li><li>Any dependencies or expected output</li></ul></li></ol><hr><h2 id=attribution>Attribution</h2><p>All notebook contributors are acknowledged on the Neurodesk <a href=https://neurodesk.org/developers/contributors/>Contributors page</a>.<br>Please include your name and a short description in your pull request using <a href=https://github.com/NeuroDesk/neurodesk.github.io/blob/main/.github/content-templates/contributor-format.md target=_blank rel=noopener>this format</a>.</p><p>Each example notebook receives a DOI for formal citation via Zenodo, ensuring your work is citable in academic contexts.</p><hr><h2 id=need-help>Need Help?</h2><p>If you have questions or would like feedback before submitting:</p><ul><li>Open a <a href=https://github.com/orgs/neurodesk/discussions target=_blank rel=noopener>discussion</a></li></ul><p>We look forward to your contributions and thank you for supporting open and reproducible neuroimaging.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-17f9fb8a06e3be71418a28e6acd4ee30>3.2 - Contribute Tutorials</h1><div class=lead>A brief guide for contributing new tutorials.</div><p>We welcome tutorials that walk users through using tools or workflows available in Neurodesk. These tutorials are valuable learning resources that support accessible, reproducible neuroimaging.</p><p>Tutorials are written in Markdown and hosted in the <a href=https://github.com/Neurodesk/neurodesk.github.io/tree/main/content/en/tutorials-examples/tutorials target=_blank rel=noopener><code>neurodesk.github.io:tutorials</code></a> repository, where they appear as part of the documentation site.</p><hr><h2 id=getting-started>Getting Started</h2><p>To contribute a new tutorial, follow the steps below:</p><h3 id=1-start-from-the-template>1. Start from the template</h3><p>Download the <a href=https://github.com/Neurodesk/neurodesk.github.io/blob/main/.github/content-templates/tutorial-template.md target=_blank rel=noopener>tutorial Markdown template</a> file from GitHub and edit it locally with your own content.</p><p>The template includes:</p><ul><li>A frontmatter block with <code>title</code>, <code>linkTitle</code>, <code>description</code>, and other metadata</li><li>A placeholder author attribution block</li><li>Section headings and content structure for a clear tutorial layout</li></ul><h3 id=2-follow-best-practices>2. Follow best practices</h3><ul><li>Use clear, descriptive section headers</li><li>Include step-by-step instructions with commands and screenshots</li><li>Store images in the appropriate <code>/static/</code> folder and link them with full paths</li><li>Write in plain Markdown, using Hugo formatting where needed</li></ul><p>See existing <a href=https://neurodesk.org/tutorials-examples/tutorials/>tutorial examples</a> for reference.</p><hr><h2 id=saving-and-submitting>Saving and Submitting</h2><p>Follow the steps for <a href=https://neurodesk.org/developers/documentation/creating-website-content>contributing content to Neurodesk.org</a></p><ol><li><p>Place your completed <code>.md</code> file in the appropriate subfolder under:</p><p><a href=https://github.com/NeuroDesk/neurodesk.github.io/tree/main/content/en/tutorials-examples/tutorials target=_blank rel=noopener><code>/content/en/tutorials-examples/tutorials/</code></a></p></li><li><p>Store any images in a matching subfolder in <code>/static/tutorials-examples/tutorials/</code></p></li><li><p>Open a pull request in the <a href=https://github.com/NeuroDesk/neurodesk.github.io target=_blank rel=noopener>neurodesk.github.io repository</a></p></li><li><p>In your pull request, include:</p><ul><li>A short summary of your tutorial</li><li>Your name and GitHub handle (if you&rsquo;d like to be credited)</li></ul></li></ol><hr><h2 id=attribution>Attribution</h2><p>All tutorial contributors are acknowledged on the <a href=https://neurodesk.org/developers/contributors/>Contributors page</a>.<br>To be listed, include your name and a short description in your pull request using <a href=https://github.com/NeuroDesk/neurodesk.github.io/blob/main/.github/content-templates/contributor-format.md target=_blank rel=noopener>this format</a>.</p><hr><h2 id=need-help>Need Help?</h2><p>If you have questions or would like feedback before submitting:</p><ul><li>Open a <a href=https://github.com/NeuroDesk/neurodesk.github.io/discussions target=_blank rel=noopener>discussion</a></li></ul><p>We appreciate your contribution to the Neurodesk community and reproducible science.</p></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=Mastodon aria-label=Mastodon><a target=_blank rel=noopener href=https://masto.ai/@Neurodesk aria-label=Mastodon><i class="fab fa-mastodon responsive-icon"></i>&nbsp;&nbsp;Mastodon</a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Discussion aria-label=Discussion><a target=_blank rel=noopener href=https://github.com/orgs/NeuroDesk/discussions aria-label=Discussion><i class="fa fa-envelope responsive-icon"></i>&nbsp;&nbsp;Discussion</a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Acknowledgements aria-label=Acknowledgements><a target=_blank rel=noopener href=https://neurodesk.org/overview/acknowledgement/ aria-label=Acknowledgements><i class="fa fa-handshake responsive-icon"></i>&nbsp;&nbsp;Acknowledgements</a></li></ul></div><div class="col-6 col-sm-4 text-end text-xs-center order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=Metrics aria-label=Metrics><a target=_blank rel=noopener href=https://neurodesk.org/docs/overview/metrics aria-label=Metrics><i class="fa fa-signal responsive-icon"></i>&nbsp;&nbsp;Metrics</a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Uptime aria-label=Uptime><a target=_blank rel=noopener href=https://stats.uptimerobot.com/NBE38IZWZM aria-label=Uptime><i class="fa fa-circle responsive-icon"></i>&nbsp;&nbsp;Uptime</a></li></ul></div><div class="td-footer__copyright-etc col-12 col-sm-4 text-center py-2 order-sm-2"></div></div></div></footer></div><script src=https://neurodesk.org/js/main.min.371147b5f79a80912e5b0a2cd8f59889c6f0ac501947707b50f470099ce2141c.js integrity="sha256-NxFHtfeagJEuWwos2PWYicbwrFAZR3B7UPRwCZziFBw=" crossorigin=anonymous></script><script defer src=https://neurodesk.org/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@docsearch/js@3.8.2 integrity="sha512-lsD+XVzdBI6ZquXc8gqbw0/bgrfIsMJwY/8xvmvbN+U3gZSeG7BXQoCq4zv/yCmntR2GLHtgB+bD4ESPsKIbIA==" crossorigin=anonymous></script><script type=text/javascript>const containers=["#docsearch-0","#docsearch-1"];for(let e of containers)docsearch({container:e,appId:"P5JEPQ5LZ2",apiKey:"56c6d9a954f7df2a98dcedb2763af8c4",indexName:"neurodesk"})</script><script src=https://neurodesk.org/js/tabpane-persist.js></script></body></html>